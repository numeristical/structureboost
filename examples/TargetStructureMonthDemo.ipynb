{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structured Multi-Class Classification with StructureBoost\n",
    "Often, in multi-class classification problems, the classes in the target variable\n",
    "possess a *structure* that would be helpful to exploit.\n",
    "\n",
    "In this notebook, we illustrate how to use StructureBoost to exploit structure\n",
    "in the target variable of multiclass classification problems.\n",
    "\n",
    "In this particular example, we will consider a problem where the month of the year is \n",
    "the target variable.  The months of the year naturally possess a circular structure as January\n",
    "is \"next to\" December in the same way that June is \"next to\" July.  We will show how exploiting\n",
    "this structure yields better predictions.  At the same time, we will learn how to configure and\n",
    "use StructureBoost to exploit the structure in categorical target variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import structureboost as stb\n",
    "import ml_insights as mli\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "pd.set_option('display.max_rows',999)\n",
    "pd.set_option('display.max_columns',999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ca = pd.read_csv('data/CA_weather_both.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data and Explore\n",
    "As you can see below, this is a dataset where each row represents the weather observations from a particular weather station on a particular date.  We know the min and max temperature (TMIN, TMAX), the amount of precipitation (PRCP), as well as the month of the observation and the county where the weather station is located.\n",
    "\n",
    "California has 58 counties, however, the weather station in Sutter County does not record temperature, so for the purposes of this exercise we are combining Sutter and Yuba counties into a single county \"Sutter_Yuba\" so that there are 57 counties.  You can see below that we have selected 5000 observations from each of the 57 counties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2438258 entries, 0 to 2438257\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Dtype  \n",
      "---  ------      -----  \n",
      " 0   county      object \n",
      " 1   month       int64  \n",
      " 2   DATE        object \n",
      " 3   STATION     object \n",
      " 4   PRCP        float64\n",
      " 5   rained      int64  \n",
      " 6   TMAX        float64\n",
      " 7   TMIN        float64\n",
      " 8   outcome     int64  \n",
      " 9   county_num  int64  \n",
      "dtypes: float64(3), int64(4), object(3)\n",
      "memory usage: 186.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df_ca.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county</th>\n",
       "      <th>month</th>\n",
       "      <th>DATE</th>\n",
       "      <th>STATION</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>rained</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>outcome</th>\n",
       "      <th>county_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1302220</th>\n",
       "      <td>Plumas</td>\n",
       "      <td>12</td>\n",
       "      <td>2017-12-21</td>\n",
       "      <td>USC00047195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894245</th>\n",
       "      <td>Merced</td>\n",
       "      <td>6</td>\n",
       "      <td>2010-06-30</td>\n",
       "      <td>USC00046168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2364683</th>\n",
       "      <td>Ventura</td>\n",
       "      <td>6</td>\n",
       "      <td>2006-06-03</td>\n",
       "      <td>USW00093110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>6</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251719</th>\n",
       "      <td>Placer</td>\n",
       "      <td>8</td>\n",
       "      <td>2000-08-27</td>\n",
       "      <td>USC00041912</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>8</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125308</th>\n",
       "      <td>Napa</td>\n",
       "      <td>8</td>\n",
       "      <td>2008-08-02</td>\n",
       "      <td>USC00047643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>8</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          county  month        DATE      STATION  PRCP  rained   TMAX  TMIN  \\\n",
       "1302220   Plumas     12  2017-12-21  USC00047195   0.0       0   39.0  17.0   \n",
       "894245    Merced      6  2010-06-30  USC00046168   0.0       0  100.0  50.0   \n",
       "2364683  Ventura      6  2006-06-03  USW00093110   0.0       0   76.0  58.0   \n",
       "1251719   Placer      8  2000-08-27  USC00041912   0.0       0   89.0  55.0   \n",
       "1125308     Napa      8  2008-08-02  USC00047643   0.0       0   93.0  56.0   \n",
       "\n",
       "         outcome  county_num  \n",
       "1302220        0          31  \n",
       "894245         6          23  \n",
       "2364683        6          54  \n",
       "1251719        8          30  \n",
       "1125308        8          27  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ca.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Los_Angeles        175657\n",
       "San_Diego          174102\n",
       "San_Bernardino     136190\n",
       "Riverside          108895\n",
       "Kern                93060\n",
       "Mono                70613\n",
       "Modoc               67155\n",
       "Siskiyou            66201\n",
       "Alameda             61539\n",
       "Alpine              59257\n",
       "El_Dorado           57529\n",
       "Santa_Barbara       55057\n",
       "Placer              54810\n",
       "Sonoma              54530\n",
       "Fresno              53523\n",
       "Nevada              52865\n",
       "Shasta              51819\n",
       "Orange              48769\n",
       "Tulare              48157\n",
       "San_Luis_Obispo     47342\n",
       "Monterey            44078\n",
       "Napa                42876\n",
       "Humboldt            40800\n",
       "Santa_Clara         38591\n",
       "Merced              37425\n",
       "Ventura             37135\n",
       "Inyo                37018\n",
       "Contra_Costa        36258\n",
       "Mendocino           35587\n",
       "Tuolumne            35418\n",
       "Kings               33282\n",
       "San_Mateo           33241\n",
       "Plumas              30979\n",
       "Butte               29809\n",
       "Imperial            29753\n",
       "Sierra              27656\n",
       "Solano              27312\n",
       "Santa_Cruz          24621\n",
       "Trinity             21620\n",
       "Sacramento          21212\n",
       "San_Joaquin         20760\n",
       "Yolo                20413\n",
       "Glenn               20300\n",
       "Yuba                18369\n",
       "Madera              17710\n",
       "Mariposa            16255\n",
       "San_Benito          15405\n",
       "Marin               14517\n",
       "Del_Norte           13793\n",
       "Stanislaus          13403\n",
       "San_Francisco       12647\n",
       "Tehama              12089\n",
       "Lassen              10639\n",
       "Calaveras           10395\n",
       "Colusa               7609\n",
       "Amador               6587\n",
       "Lake                 5626\n",
       "Name: county, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ca.county.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     212138\n",
       "1     211252\n",
       "5     208736\n",
       "7     208343\n",
       "8     207582\n",
       "4     203631\n",
       "10    201396\n",
       "6     200072\n",
       "12    199238\n",
       "9     198255\n",
       "11    194061\n",
       "2     193554\n",
       "Name: month, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ca.month.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "First, we are going to build a model that tries to predict the month of the year, given the min and max temperature (TMIN, TMAX) and the amount of precipitation (PRCP).  In general, we don't expect to be able to predict the month exactly, but we would like to have an accurate probability distribution on what month it is given the temperatures and precipitation that day.  Thus we will use the `log_loss` to determine the quality of our predictions.\n",
    "\n",
    "Clearly, there is some meaningful *structure* in the target variable month.  We expect the weather in January to be more similar to December than it is to July.  Thus, it is reasonable to expect that we will get better performance if the model is aware of these similarities during training, rather than just knowing that months are different from one another.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_ca.month)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As would be expected, the months are numbered 1 through 12.  StructureBoost requires the target to be integers from 0 to num_classes-1.  Thus, we will create a modified \"month\" variable where December (12) is designated as 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvec = df_ca['month'].copy()\n",
    "tvec[tvec==12] = 0\n",
    "df_ca['month_mod'] = tvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_ca.month_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll split the data into training, validation, and test_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_list = ['TMAX','TMIN','PRCP']\n",
    "target = 'month_mod'\n",
    "\n",
    "X = df_ca.loc[:,feat_list]\n",
    "y = df_ca[target]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 3), (5000, 3), (100000, 3), (2332258, 3))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here we can configure the sizes of our training, validation and test sets (and the rest will be a \"remainder\")\n",
    "train_size = 1000\n",
    "valid_size = 5000\n",
    "test_size = 100000\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X,y,test_size=test_size, random_state=42)\n",
    "X_train_rem, X_valid, y_train_rem, y_valid = train_test_split(X_train_val, y_train_val, test_size=valid_size, random_state=42)\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X_train_rem, y_train_rem, train_size=train_size, random_state=42)\n",
    "X_train.shape, X_valid.shape, X_test.shape, X_rem.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring StructureBoost Target Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StructureBoost permits two methods for defining the structure on a target variable:\n",
    "\n",
    "    1. Using a fixed set of partitions (with corresponding weights)\n",
    "    2. Using a graph, and randomly choosing partitions from the graph.\n",
    "\n",
    "The idea is that the partitions provide meaningful \"coarsenings\" of the target state space.  The loss function, will then be able to take into account that values in the same *block* of the partition are similar.  The beauty of this approach is that we can use many partitions at the same time.\n",
    "\n",
    "For example, for the months of the year, one might consider that the months of each season tend to have similar weather.  This might lead us to define a partition of the months such as:\n",
    "{Dec, Jan, Feb}, {Mar, Apr, May}, {Jun, Jul, Aug}, {Sep, Oct, Nov}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TMAX': {'feature_type': 'numerical', 'max_splits_to_search': 25},\n",
       " 'TMIN': {'feature_type': 'numerical', 'max_splits_to_search': 25},\n",
       " 'PRCP': {'feature_type': 'numerical', 'max_splits_to_search': 25}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a quick way to get a starting feature configuration that can be modified\n",
    "fc1 = stb.get_basic_config(X_train, stb.default_config_dict())\n",
    "fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will run StructureBoost with no knowledge of the structure of the months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=0, eval_set_loss = 2.4863196197521864\n",
      "i=10, eval_set_loss = 2.396329473329679\n",
      "i=20, eval_set_loss = 2.336955701546618\n",
      "i=30, eval_set_loss = 2.2938272762671645\n",
      "i=40, eval_set_loss = 2.2625749711851126\n",
      "i=50, eval_set_loss = 2.2416198645540355\n",
      "i=60, eval_set_loss = 2.226324293892515\n",
      "i=70, eval_set_loss = 2.214557961034477\n",
      "i=80, eval_set_loss = 2.207146528026032\n",
      "i=90, eval_set_loss = 2.201777303378781\n",
      "i=100, eval_set_loss = 2.197241427537696\n",
      "i=110, eval_set_loss = 2.194089316466146\n",
      "i=120, eval_set_loss = 2.1915613509170804\n",
      "i=130, eval_set_loss = 2.189987787794744\n",
      "i=140, eval_set_loss = 2.1888735567884097\n",
      "i=150, eval_set_loss = 2.188989224197152\n",
      "Stopping early: curr_loss of 2.188989224197152\n",
      "                                        exceeds compare_loss of 2.1888735567884097\n"
     ]
    }
   ],
   "source": [
    "# Define the StructureBoost model and fit it\n",
    "stb0 = stb.StructureBoostMulti(num_trees=2000, feature_configs=fc1, num_classes=12, \n",
    "                               target_structure=None, learning_rate=.02)\n",
    "stb0.fit(X_train,y_train, eval_set=(X_valid, y_valid), early_stop_past_steps=1, eval_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.193247374040555"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on a test set, and then evaluate the log_loss\n",
    "test_preds_0 = stb0.predict_proba(X_test)\n",
    "log_loss(y_test, test_preds_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will configure StructureBoost using a fixed set of partitions.  We will group the months in \"blocks\" of size 3 - and there are 3 different partitions, depending on where we start grouping.\n",
    "\n",
    "StructureBoost assumes you will always use the singleton partition as part of the partition set.  We give a weight using the `singleton_weight` parameter.\n",
    "\n",
    "The weights for the other partitions in the partition set must be designated by the `partition_weight_vec` parameter.  The weights should sum to 1.  (you will get a warning, but not an error, if this is not the case).\n",
    "\n",
    "In the example below, the singleton partition has weight 0.4 and the other 3 partitions each have weight 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we configure the target structure to use a fixed, weighted partition\n",
    "ts1 = {}\n",
    "ts1['partition_type'] = 'fixed'\n",
    "ts1['singleton_weight'] = .4\n",
    "ts1['partition_list'] = [ [[0,1,2],[3,4,5],[6,7,8],[9,10,11]],\n",
    "                         [[1,2,3],[4,5,6],[7,8,9],[10,11,0]],\n",
    "                         [[2,3,4],[5,6,7],[8,9,10],[11,0,1]] ]\n",
    "ts1['partition_weight_vec'] = [.2,.2,.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=0, eval_set_loss = 2.4863196197521864\n",
      "i=10, eval_set_loss = 2.4047244510636046\n",
      "i=20, eval_set_loss = 2.346128614124593\n",
      "i=30, eval_set_loss = 2.301997592514495\n",
      "i=40, eval_set_loss = 2.269423968030633\n",
      "i=50, eval_set_loss = 2.2471942956475366\n",
      "i=60, eval_set_loss = 2.229287716246167\n",
      "i=70, eval_set_loss = 2.2158349946189695\n",
      "i=80, eval_set_loss = 2.206075487011261\n",
      "i=90, eval_set_loss = 2.1982732675754764\n",
      "i=100, eval_set_loss = 2.192963263661323\n",
      "i=110, eval_set_loss = 2.1890845025375456\n",
      "i=120, eval_set_loss = 2.1855804025213357\n",
      "i=130, eval_set_loss = 2.18340423205977\n",
      "i=140, eval_set_loss = 2.1818524445856773\n",
      "i=150, eval_set_loss = 2.1810957607126715\n",
      "i=160, eval_set_loss = 2.1801758840654015\n",
      "i=170, eval_set_loss = 2.1800223868023356\n",
      "i=180, eval_set_loss = 2.180336097887871\n",
      "Stopping early: curr_loss of 2.180336097887871\n",
      "                                        exceeds compare_loss of 2.1800223868023356\n"
     ]
    }
   ],
   "source": [
    "# Define the StructureBoost model and fit it\n",
    "stb1 = stb.StructureBoostMulti(num_trees=2000, feature_configs=fc1, num_classes=12, \n",
    "                               target_structure=ts1, learning_rate=.02)\n",
    "\n",
    "stb1.fit(X_train,y_train, eval_set=(X_valid, y_valid), early_stop_past_steps=1, eval_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.182813918607703"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on a test set, and then evaluate the log_loss\n",
    "test_preds_1 = stb1.predict_proba(X_test)\n",
    "log_loss(y_test, test_preds_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In some cases it may be tedious to write out a fixed partition.  There is an alternative, when the desired structure can be represented in terms of a *graph*.  In this case we can simply provide the graph and ask StructureBoost to randomly find partitions of the graph (which respect the structure of the graph).  Then, at each iteration, a different, randomly chosen partition (or partitions) of the graph will be used, in conjunction with the singleton partition.\n",
    "\n",
    "We show how to configure this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11},\n",
       " {frozenset({3, 4}),\n",
       "  frozenset({2, 3}),\n",
       "  frozenset({9, 10}),\n",
       "  frozenset({1, 2}),\n",
       "  frozenset({4, 5}),\n",
       "  frozenset({0, 1}),\n",
       "  frozenset({6, 7}),\n",
       "  frozenset({8, 9}),\n",
       "  frozenset({7, 8}),\n",
       "  frozenset({5, 6}),\n",
       "  frozenset({0, 11}),\n",
       "  frozenset({10, 11})})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First we must define the appropriate graph\n",
    "cycle_0_11 = stb.graphs.cycle_int_graph(0,11)\n",
    "cycle_0_11.vertices, cycle_0_11.edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we configure the target structure to use a variable (random) partition\n",
    "# We must specify how many partitions we want, and of what sizes\n",
    "# Note: partition size refers to the *number* of blocks, not the size of the blocks\n",
    "\n",
    "ts2a = {}\n",
    "ts2a['partition_type'] = 'variable'\n",
    "ts2a['target_graph'] = cycle_0_11\n",
    "ts2a['singleton_weight'] = .5\n",
    "ts2a['num_partitions'] = 1\n",
    "ts2a['random_partition_size'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'rp_method' not configured. Defaulting to 'span_tree'\n",
      "i=0, eval_set_loss = 2.4863196197521864\n",
      "i=10, eval_set_loss = 2.401244761203578\n",
      "i=20, eval_set_loss = 2.341656565548186\n",
      "i=30, eval_set_loss = 2.299529924977251\n",
      "i=40, eval_set_loss = 2.2702340870338986\n",
      "i=50, eval_set_loss = 2.248428144503627\n",
      "i=60, eval_set_loss = 2.231352335656243\n",
      "i=70, eval_set_loss = 2.2182466161638645\n",
      "i=80, eval_set_loss = 2.2090936980161087\n",
      "i=90, eval_set_loss = 2.2017913503093895\n",
      "i=100, eval_set_loss = 2.196086691848278\n",
      "i=110, eval_set_loss = 2.1919235319860313\n",
      "i=120, eval_set_loss = 2.1885419631702256\n",
      "i=130, eval_set_loss = 2.187427164547418\n",
      "i=140, eval_set_loss = 2.1850895051035963\n",
      "i=150, eval_set_loss = 2.184308935881505\n",
      "i=160, eval_set_loss = 2.1831796199678886\n",
      "i=170, eval_set_loss = 2.182624973247668\n",
      "i=180, eval_set_loss = 2.1828014138362777\n",
      "Stopping early: curr_loss of 2.1828014138362777\n",
      "                                        exceeds compare_loss of 2.182624973247668\n"
     ]
    }
   ],
   "source": [
    "stb2a = stb.StructureBoostMulti(num_trees=2000, feature_configs=fc1, num_classes=12, \n",
    "                               target_structure=ts2a, learning_rate=.02)\n",
    "\n",
    "stb2a.fit(X_train,y_train, eval_set=(X_valid, y_valid), early_stop_past_steps=1, eval_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.186071577939376"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on a test set, and then evaluate the log_loss\n",
    "test_preds_2a = stb2a.predict_proba(X_test)\n",
    "log_loss(y_test, test_preds_2a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This time, let's configure it so that there are multiple partitions, of various sizes\n",
    "# Each partition is given the same weight (= (1-singleton_weight)/num_partitions))\n",
    "ts2b = {}\n",
    "ts2b['partition_type'] = 'variable'\n",
    "ts2b['target_graph'] = cycle_0_11\n",
    "ts2b['singleton_weight'] = .5\n",
    "ts2b['num_partitions'] = 5\n",
    "ts2b['random_partition_size'] = [3,3,4,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'rp_method' not configured. Defaulting to 'span_tree'\n",
      "i=0, eval_set_loss = 2.4863196197521864\n",
      "i=10, eval_set_loss = 2.401912209182192\n",
      "i=20, eval_set_loss = 2.344967414865193\n",
      "i=30, eval_set_loss = 2.3020662928779325\n",
      "i=40, eval_set_loss = 2.2715219256139765\n",
      "i=50, eval_set_loss = 2.2491298690083843\n",
      "i=60, eval_set_loss = 2.232459636374094\n",
      "i=70, eval_set_loss = 2.219026128548193\n",
      "i=80, eval_set_loss = 2.20898922240422\n",
      "i=90, eval_set_loss = 2.2020277635182444\n",
      "i=100, eval_set_loss = 2.1969143125996435\n",
      "i=110, eval_set_loss = 2.193469456284114\n",
      "i=120, eval_set_loss = 2.190387602737842\n",
      "i=130, eval_set_loss = 2.188009829337936\n",
      "i=140, eval_set_loss = 2.1860273230675693\n",
      "i=150, eval_set_loss = 2.1844104060271277\n",
      "i=160, eval_set_loss = 2.183359551615954\n",
      "i=170, eval_set_loss = 2.1825701912486415\n",
      "i=180, eval_set_loss = 2.1828596846273562\n",
      "Stopping early: curr_loss of 2.1828596846273562\n",
      "                                        exceeds compare_loss of 2.1825701912486415\n"
     ]
    }
   ],
   "source": [
    "stb2b = stb.StructureBoostMulti(num_trees=2000, feature_configs=fc1, num_classes=12, \n",
    "                               target_structure=ts2b, learning_rate=.02)\n",
    "\n",
    "stb2b.fit(X_train,y_train, eval_set=(X_valid, y_valid), early_stop_past_steps=1, eval_freq=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.186598535214227"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions on a test set, and then evaluate the log_loss\n",
    "test_preds_2b = stb2b.predict_proba(X_test)\n",
    "log_loss(y_test, test_preds_2b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Rigorous testing, Varying the singleton weight\n",
    "Let's see how this does as we vary the singleton weight from 0.0 to 1.0: Note that a singleton weight of 0 is not recommended, as it means there is no \"incentive\" to get the month exactly right.  A singleton weight of 1 means that we are not using the structure at all - it is equivalent to setting `target_structure=None` (using a classical approach to multi-classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "feat_list = ['TMAX','TMIN','PRCP']\n",
    "target = 'month_mod'\n",
    "\n",
    "X = df_ca.loc[:,feat_list]\n",
    "y = df_ca[target]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Singleton weight = 0.0\n",
      "trial_number = 0\n",
      "i=0, eval_set_loss = 2.4852320238721184\n",
      "i=10, eval_set_loss = 2.4169632783160107\n",
      "i=20, eval_set_loss = 2.3626312866163715\n",
      "i=30, eval_set_loss = 2.319693830429316\n",
      "i=40, eval_set_loss = 2.2865504673705526\n",
      "i=50, eval_set_loss = 2.2604589892294866\n",
      "i=60, eval_set_loss = 2.240669799307921\n",
      "i=70, eval_set_loss = 2.2248812021523277\n",
      "i=80, eval_set_loss = 2.2127637098569255\n",
      "i=90, eval_set_loss = 2.2027594173568525\n",
      "i=100, eval_set_loss = 2.1949093706741\n",
      "i=110, eval_set_loss = 2.1886972490440963\n",
      "i=120, eval_set_loss = 2.1835924073681805\n",
      "i=130, eval_set_loss = 2.17918367609976\n",
      "i=140, eval_set_loss = 2.17551127361595\n",
      "i=150, eval_set_loss = 2.1725463333444845\n",
      "i=160, eval_set_loss = 2.1696330858975506\n",
      "i=170, eval_set_loss = 2.167227005634237\n",
      "i=180, eval_set_loss = 2.165141829335148\n",
      "i=190, eval_set_loss = 2.1638127671615015\n",
      "i=200, eval_set_loss = 2.161912677306178\n",
      "i=210, eval_set_loss = 2.1600838572717875\n",
      "i=220, eval_set_loss = 2.1588877072619304\n",
      "i=230, eval_set_loss = 2.1621649859849943\n",
      "Stopping early: curr_loss of 2.1621649859849943\n",
      "                                        exceeds compare_loss of 2.1588877072619304\n",
      "Singleton weight = 0.1\n",
      "trial_number = 0\n",
      "i=0, eval_set_loss = 2.4852320238721184\n",
      "i=10, eval_set_loss = 2.4004578735757147\n",
      "i=20, eval_set_loss = 2.339097457739602\n",
      "i=30, eval_set_loss = 2.29355404677186\n",
      "i=40, eval_set_loss = 2.2606581915782145\n",
      "i=50, eval_set_loss = 2.2353496491947715\n",
      "i=60, eval_set_loss = 2.216179998210293\n",
      "i=70, eval_set_loss = 2.201280445240773\n",
      "i=80, eval_set_loss = 2.1896818665516595\n",
      "i=90, eval_set_loss = 2.1807580189250504\n",
      "i=100, eval_set_loss = 2.173793105116037\n",
      "i=110, eval_set_loss = 2.168270267195224\n",
      "i=120, eval_set_loss = 2.1638730644553505\n",
      "i=130, eval_set_loss = 2.159954951667923\n",
      "i=140, eval_set_loss = 2.15668769347177\n",
      "i=150, eval_set_loss = 2.15412964750229\n",
      "i=160, eval_set_loss = 2.1517909278535736\n",
      "i=170, eval_set_loss = 2.149950877420543\n",
      "i=180, eval_set_loss = 2.1488212911302966\n",
      "i=190, eval_set_loss = 2.147771459567605\n",
      "i=200, eval_set_loss = 2.146732700407816\n",
      "i=210, eval_set_loss = 2.145842384295871\n",
      "i=220, eval_set_loss = 2.1449420377885042\n",
      "i=230, eval_set_loss = 2.1444385344142662\n",
      "i=240, eval_set_loss = 2.143840649414635\n",
      "i=250, eval_set_loss = 2.143471041601939\n",
      "i=260, eval_set_loss = 2.1427177440194507\n",
      "i=270, eval_set_loss = 2.1424057800876284\n",
      "i=280, eval_set_loss = 2.142262041277042\n",
      "i=290, eval_set_loss = 2.142012264526121\n",
      "i=300, eval_set_loss = 2.141848473383741\n",
      "i=310, eval_set_loss = 2.141474367807359\n",
      "i=320, eval_set_loss = 2.141348952111391\n",
      "i=330, eval_set_loss = 2.1415102965438435\n",
      "Stopping early: curr_loss of 2.1415102965438435\n",
      "                                        exceeds compare_loss of 2.141348952111391\n",
      "Singleton weight = 0.2\n",
      "trial_number = 0\n",
      "i=0, eval_set_loss = 2.4852320238721184\n",
      "i=10, eval_set_loss = 2.3997204439483313\n",
      "i=20, eval_set_loss = 2.338002775382274\n",
      "i=30, eval_set_loss = 2.292462092574365\n",
      "i=40, eval_set_loss = 2.2592219566923966\n",
      "i=50, eval_set_loss = 2.233941428802976\n",
      "i=60, eval_set_loss = 2.215359001247119\n",
      "i=70, eval_set_loss = 2.2006570191110026\n",
      "i=80, eval_set_loss = 2.1892310499958794\n",
      "i=90, eval_set_loss = 2.180248595847075\n",
      "i=100, eval_set_loss = 2.1732067119538083\n",
      "i=110, eval_set_loss = 2.1675222651101627\n",
      "i=120, eval_set_loss = 2.163256353571898\n",
      "i=130, eval_set_loss = 2.1597613678887386\n",
      "i=140, eval_set_loss = 2.1567619036424572\n",
      "i=150, eval_set_loss = 2.1545461870785787\n",
      "i=160, eval_set_loss = 2.1522523272571665\n",
      "i=170, eval_set_loss = 2.150420576518379\n",
      "i=180, eval_set_loss = 2.1489430757477987\n",
      "i=190, eval_set_loss = 2.147537037703878\n",
      "i=200, eval_set_loss = 2.146521792053173\n",
      "i=210, eval_set_loss = 2.1455612494470153\n",
      "i=220, eval_set_loss = 2.144640556778277\n",
      "i=230, eval_set_loss = 2.144228614840747\n",
      "i=240, eval_set_loss = 2.14371051890324\n",
      "i=250, eval_set_loss = 2.143240444508422\n",
      "i=260, eval_set_loss = 2.1426146175593495\n",
      "i=270, eval_set_loss = 2.142369204540767\n",
      "i=280, eval_set_loss = 2.1420647733922045\n",
      "i=290, eval_set_loss = 2.1418831968507956\n",
      "i=300, eval_set_loss = 2.1418143999846566\n",
      "i=310, eval_set_loss = 2.1417343263827124\n",
      "i=320, eval_set_loss = 2.14178163222531\n",
      "Stopping early: curr_loss of 2.14178163222531\n",
      "                                        exceeds compare_loss of 2.1417343263827124\n",
      "Singleton weight = 0.3\n",
      "trial_number = 0\n",
      "i=0, eval_set_loss = 2.4852320238721184\n",
      "i=10, eval_set_loss = 2.398744471253848\n",
      "i=20, eval_set_loss = 2.336714587397623\n",
      "i=30, eval_set_loss = 2.2911099089106077\n",
      "i=40, eval_set_loss = 2.2578737154581097\n",
      "i=50, eval_set_loss = 2.2326967185174538\n",
      "i=60, eval_set_loss = 2.214249336917903\n",
      "i=70, eval_set_loss = 2.199666324181579\n",
      "i=80, eval_set_loss = 2.1883679611350604\n",
      "i=90, eval_set_loss = 2.17947309808155\n",
      "i=100, eval_set_loss = 2.172554281331209\n",
      "i=110, eval_set_loss = 2.167377837041575\n",
      "i=120, eval_set_loss = 2.163034436497252\n",
      "i=130, eval_set_loss = 2.1593421852376715\n",
      "i=140, eval_set_loss = 2.1561128224796016\n",
      "i=150, eval_set_loss = 2.1536674963979645\n",
      "i=160, eval_set_loss = 2.151552535317183\n",
      "i=170, eval_set_loss = 2.1499203389037462\n",
      "i=180, eval_set_loss = 2.148619298291547\n",
      "i=190, eval_set_loss = 2.14738926429965\n",
      "i=200, eval_set_loss = 2.1465033112583405\n",
      "i=210, eval_set_loss = 2.14572122600336\n",
      "i=220, eval_set_loss = 2.145152042106273\n",
      "i=230, eval_set_loss = 2.1445678527680516\n",
      "i=240, eval_set_loss = 2.1441328868962226\n",
      "i=250, eval_set_loss = 2.1437727448532646\n",
      "i=260, eval_set_loss = 2.143162932494282\n",
      "i=270, eval_set_loss = 2.1430931803940636\n",
      "i=280, eval_set_loss = 2.142950444038348\n",
      "i=290, eval_set_loss = 2.142748582984009\n",
      "i=300, eval_set_loss = 2.142615992311483\n",
      "i=310, eval_set_loss = 2.1422858462512733\n",
      "i=320, eval_set_loss = 2.142440333960812\n",
      "Stopping early: curr_loss of 2.142440333960812\n",
      "                                        exceeds compare_loss of 2.1422858462512733\n",
      "Singleton weight = 0.4\n",
      "trial_number = 0\n",
      "i=0, eval_set_loss = 2.4852320238721184\n",
      "i=10, eval_set_loss = 2.397754841920654\n",
      "i=20, eval_set_loss = 2.3355464180547494\n",
      "i=30, eval_set_loss = 2.289877985755686\n",
      "i=40, eval_set_loss = 2.2571478420085636\n",
      "i=50, eval_set_loss = 2.2319604278576306\n",
      "i=60, eval_set_loss = 2.2135757380595664\n",
      "i=70, eval_set_loss = 2.1992026282914163\n",
      "i=80, eval_set_loss = 2.1881211571476373\n",
      "i=90, eval_set_loss = 2.1788866659975827\n",
      "i=100, eval_set_loss = 2.171604582374687\n",
      "i=110, eval_set_loss = 2.1662222781217744\n",
      "i=120, eval_set_loss = 2.1618386940601266\n",
      "i=130, eval_set_loss = 2.1580968060754584\n",
      "i=140, eval_set_loss = 2.155072016031988\n",
      "i=150, eval_set_loss = 2.1528983097938035\n",
      "i=160, eval_set_loss = 2.150877800971958\n",
      "i=170, eval_set_loss = 2.149078118306448\n",
      "i=180, eval_set_loss = 2.1475730694297708\n",
      "i=190, eval_set_loss = 2.1464971247938016\n",
      "i=200, eval_set_loss = 2.1457562659896934\n",
      "i=210, eval_set_loss = 2.1449565659689127\n",
      "i=220, eval_set_loss = 2.144167105175027\n",
      "i=230, eval_set_loss = 2.1438491794330847\n",
      "i=240, eval_set_loss = 2.143348387374577\n",
      "i=250, eval_set_loss = 2.1429336983748777\n",
      "i=260, eval_set_loss = 2.1423876532455104\n",
      "i=270, eval_set_loss = 2.1422276048790176\n",
      "i=280, eval_set_loss = 2.1421383758203314\n",
      "i=290, eval_set_loss = 2.1421835993765312\n",
      "Stopping early: curr_loss of 2.1421835993765312\n",
      "                                        exceeds compare_loss of 2.1421383758203314\n",
      "Singleton weight = 0.5\n",
      "trial_number = 0\n",
      "i=0, eval_set_loss = 2.4852320238721184\n",
      "i=10, eval_set_loss = 2.396706971117892\n",
      "i=20, eval_set_loss = 2.33367035780518\n",
      "i=30, eval_set_loss = 2.2875535066741013\n",
      "i=40, eval_set_loss = 2.254936605864854\n",
      "i=50, eval_set_loss = 2.230198775653725\n",
      "i=60, eval_set_loss = 2.2114686898572153\n",
      "i=70, eval_set_loss = 2.1970525772071667\n",
      "i=80, eval_set_loss = 2.1863869922104326\n",
      "i=90, eval_set_loss = 2.1775827508170034\n",
      "i=100, eval_set_loss = 2.17090568382993\n",
      "i=110, eval_set_loss = 2.165842947776812\n",
      "i=120, eval_set_loss = 2.161883077873317\n",
      "i=130, eval_set_loss = 2.1583568951255727\n",
      "i=140, eval_set_loss = 2.155696378699415\n",
      "i=150, eval_set_loss = 2.1534982139680223\n",
      "i=160, eval_set_loss = 2.15186940355717\n",
      "i=170, eval_set_loss = 2.150068624685487\n",
      "i=180, eval_set_loss = 2.1488136567033407\n",
      "i=190, eval_set_loss = 2.1474698241307726\n",
      "i=200, eval_set_loss = 2.1463394506841778\n",
      "i=210, eval_set_loss = 2.1455494888057656\n",
      "i=220, eval_set_loss = 2.14462180629191\n",
      "i=230, eval_set_loss = 2.144110595409647\n",
      "i=240, eval_set_loss = 2.143567972544818\n",
      "i=250, eval_set_loss = 2.1431509437653653\n",
      "i=260, eval_set_loss = 2.1423611493832344\n",
      "i=270, eval_set_loss = 2.1422633353407616\n",
      "i=280, eval_set_loss = 2.142122373547836\n",
      "i=290, eval_set_loss = 2.141933809926438\n",
      "i=300, eval_set_loss = 2.1419132218724726\n",
      "i=310, eval_set_loss = 2.141564210296169\n",
      "i=320, eval_set_loss = 2.1417675314753963\n",
      "Stopping early: curr_loss of 2.1417675314753963\n",
      "                                        exceeds compare_loss of 2.141564210296169\n",
      "Singleton weight = 0.6\n",
      "trial_number = 0\n",
      "i=0, eval_set_loss = 2.4852320238721184\n",
      "i=10, eval_set_loss = 2.3951412991275056\n",
      "i=20, eval_set_loss = 2.3320124127570785\n",
      "i=30, eval_set_loss = 2.2863329627126854\n",
      "i=40, eval_set_loss = 2.2532137089519426\n",
      "i=50, eval_set_loss = 2.2286824248089268\n",
      "i=60, eval_set_loss = 2.210710956862067\n",
      "i=70, eval_set_loss = 2.1968363599022878\n",
      "i=80, eval_set_loss = 2.185972733985348\n",
      "i=90, eval_set_loss = 2.1766928119124294\n",
      "i=100, eval_set_loss = 2.170012997663995\n",
      "i=110, eval_set_loss = 2.1646643252726165\n",
      "i=120, eval_set_loss = 2.160758161159655\n",
      "i=130, eval_set_loss = 2.1574003025994886\n",
      "i=140, eval_set_loss = 2.15462288872102\n",
      "i=150, eval_set_loss = 2.1523874570562986\n",
      "i=160, eval_set_loss = 2.1506953226402463\n",
      "i=170, eval_set_loss = 2.1489781413969453\n",
      "i=180, eval_set_loss = 2.147821811795094\n",
      "i=190, eval_set_loss = 2.146704455170256\n",
      "i=200, eval_set_loss = 2.145865837190967\n",
      "i=210, eval_set_loss = 2.1451663018813707\n",
      "i=220, eval_set_loss = 2.1441586077252315\n",
      "i=230, eval_set_loss = 2.1438247566259623\n",
      "i=240, eval_set_loss = 2.143502837094996\n",
      "i=250, eval_set_loss = 2.143179033724646\n",
      "i=260, eval_set_loss = 2.1427026210853417\n",
      "i=270, eval_set_loss = 2.142459957157986\n",
      "i=280, eval_set_loss = 2.142285548366744\n",
      "i=290, eval_set_loss = 2.1423812233942083\n",
      "Stopping early: curr_loss of 2.1423812233942083\n",
      "                                        exceeds compare_loss of 2.142285548366744\n",
      "Singleton weight = 0.7\n",
      "trial_number = 0\n",
      "i=0, eval_set_loss = 2.4852320238721184\n",
      "i=10, eval_set_loss = 2.3934519843349835\n",
      "i=20, eval_set_loss = 2.3298819039419807\n",
      "i=30, eval_set_loss = 2.2841597909000515\n",
      "i=40, eval_set_loss = 2.2511968192126397\n",
      "i=50, eval_set_loss = 2.2265066516199337\n",
      "i=60, eval_set_loss = 2.2088658939525456\n",
      "i=70, eval_set_loss = 2.1953020966609875\n",
      "i=80, eval_set_loss = 2.184507275753536\n",
      "i=90, eval_set_loss = 2.176199859169419\n",
      "i=100, eval_set_loss = 2.1698616983584076\n",
      "i=110, eval_set_loss = 2.1646792821038554\n",
      "i=120, eval_set_loss = 2.160700073575347\n",
      "i=130, eval_set_loss = 2.157790848451283\n",
      "i=140, eval_set_loss = 2.1548649098975763\n",
      "i=150, eval_set_loss = 2.152652059351247\n",
      "i=160, eval_set_loss = 2.150883419877716\n",
      "i=170, eval_set_loss = 2.149274581322611\n",
      "i=180, eval_set_loss = 2.1479245155043682\n",
      "i=190, eval_set_loss = 2.14715818254611\n",
      "i=200, eval_set_loss = 2.146445036564107\n",
      "i=210, eval_set_loss = 2.145616718614979\n",
      "i=220, eval_set_loss = 2.1449942188979616\n",
      "i=230, eval_set_loss = 2.1447335262674425\n",
      "i=240, eval_set_loss = 2.1442923852442393\n",
      "i=250, eval_set_loss = 2.1441570667540786\n",
      "i=260, eval_set_loss = 2.1435131219858214\n",
      "i=270, eval_set_loss = 2.1433776560671634\n",
      "i=280, eval_set_loss = 2.1431799393310493\n",
      "i=290, eval_set_loss = 2.143370319559422\n",
      "Stopping early: curr_loss of 2.143370319559422\n",
      "                                        exceeds compare_loss of 2.1431799393310493\n",
      "Singleton weight = 0.8\n",
      "trial_number = 0\n",
      "i=0, eval_set_loss = 2.4852320238721184\n",
      "i=10, eval_set_loss = 2.391531745291117\n",
      "i=20, eval_set_loss = 2.327488589935448\n",
      "i=30, eval_set_loss = 2.281834758146171\n",
      "i=40, eval_set_loss = 2.249366077360621\n",
      "i=50, eval_set_loss = 2.225272443646626\n",
      "i=60, eval_set_loss = 2.2072880331699265\n",
      "i=70, eval_set_loss = 2.1932284854366095\n",
      "i=80, eval_set_loss = 2.182739431023341\n",
      "i=90, eval_set_loss = 2.1745098573477533\n",
      "i=100, eval_set_loss = 2.1681142007707925\n",
      "i=110, eval_set_loss = 2.163374708688299\n",
      "i=120, eval_set_loss = 2.1596465028928664\n",
      "i=130, eval_set_loss = 2.156430950525478\n",
      "i=140, eval_set_loss = 2.1539337090608934\n",
      "i=150, eval_set_loss = 2.1518465561489464\n",
      "i=160, eval_set_loss = 2.150301947165138\n",
      "i=170, eval_set_loss = 2.1488883786946573\n",
      "i=180, eval_set_loss = 2.147403618856576\n",
      "i=190, eval_set_loss = 2.1463871032935544\n",
      "i=200, eval_set_loss = 2.1457969722060004\n",
      "i=210, eval_set_loss = 2.1451716566818386\n",
      "i=220, eval_set_loss = 2.144673590322317\n",
      "i=230, eval_set_loss = 2.144253099350858\n",
      "i=240, eval_set_loss = 2.1440173696067553\n",
      "i=250, eval_set_loss = 2.144066133413094\n",
      "Stopping early: curr_loss of 2.144066133413094\n",
      "                                        exceeds compare_loss of 2.1440173696067553\n",
      "Singleton weight = 0.9\n",
      "trial_number = 0\n",
      "i=0, eval_set_loss = 2.4852320238721184\n",
      "i=10, eval_set_loss = 2.3891938488816953\n",
      "i=20, eval_set_loss = 2.3246049876805928\n",
      "i=30, eval_set_loss = 2.2796301510944796\n",
      "i=40, eval_set_loss = 2.2475669365486572\n",
      "i=50, eval_set_loss = 2.2236653199698155\n",
      "i=60, eval_set_loss = 2.2058127042362727\n",
      "i=70, eval_set_loss = 2.1921368345521963\n",
      "i=80, eval_set_loss = 2.1816907096925666\n",
      "i=90, eval_set_loss = 2.1737449603985146\n",
      "i=100, eval_set_loss = 2.16759974224769\n",
      "i=110, eval_set_loss = 2.162780408795766\n",
      "i=120, eval_set_loss = 2.159105584003183\n",
      "i=130, eval_set_loss = 2.1556938988593624\n",
      "i=140, eval_set_loss = 2.1533090061423157\n",
      "i=150, eval_set_loss = 2.1516301877576107\n",
      "i=160, eval_set_loss = 2.149861810011969\n",
      "i=170, eval_set_loss = 2.148288666982686\n",
      "i=180, eval_set_loss = 2.147309663050014\n",
      "i=190, eval_set_loss = 2.1465273399222133\n",
      "i=200, eval_set_loss = 2.146106852119621\n",
      "i=210, eval_set_loss = 2.145580355989417\n",
      "i=220, eval_set_loss = 2.1450237668735417\n",
      "i=230, eval_set_loss = 2.1451112881255643\n",
      "Stopping early: curr_loss of 2.1451112881255643\n",
      "                                        exceeds compare_loss of 2.1450237668735417\n",
      "Singleton weight = 1.0\n",
      "trial_number = 0\n",
      "i=0, eval_set_loss = 2.4852320238721184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/xr46tkk15h10554_3mptdjlw0000gn/T/ipykernel_16166/2983974394.py:30: UserWarning: Some weights are not positive - may cause unexpected results\n",
      "  stb_tmp = stb.StructureBoostMulti(num_trees=2000, feature_configs=fc1, num_classes=12, target_structure=ts, learning_rate=.02)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=10, eval_set_loss = 2.3862752751596332\n",
      "i=20, eval_set_loss = 2.3210659080273306\n",
      "i=30, eval_set_loss = 2.275979239388689\n",
      "i=40, eval_set_loss = 2.2445336291043136\n",
      "i=50, eval_set_loss = 2.2210633512978255\n",
      "i=60, eval_set_loss = 2.203711384005885\n",
      "i=70, eval_set_loss = 2.1901418964427095\n",
      "i=80, eval_set_loss = 2.1801776148315644\n",
      "i=90, eval_set_loss = 2.1723678319923887\n",
      "i=100, eval_set_loss = 2.166562333528947\n",
      "i=110, eval_set_loss = 2.16207015345831\n",
      "i=120, eval_set_loss = 2.158521793018603\n",
      "i=130, eval_set_loss = 2.155623124965278\n",
      "i=140, eval_set_loss = 2.1533063023453214\n",
      "i=150, eval_set_loss = 2.151005363416668\n",
      "i=160, eval_set_loss = 2.1497726174492033\n",
      "i=170, eval_set_loss = 2.148606074892727\n",
      "i=180, eval_set_loss = 2.1477498234069383\n",
      "i=190, eval_set_loss = 2.146781199459264\n",
      "i=200, eval_set_loss = 2.1462697520167167\n",
      "i=210, eval_set_loss = 2.1455971865494337\n",
      "i=220, eval_set_loss = 2.1451225916003422\n",
      "i=230, eval_set_loss = 2.1448364872182015\n",
      "i=240, eval_set_loss = 2.14461290478501\n",
      "i=250, eval_set_loss = 2.1446410011980084\n",
      "Stopping early: curr_loss of 2.1446410011980084\n",
      "                                        exceeds compare_loss of 2.14461290478501\n",
      "Singleton weight = 0.0\n",
      "trial_number = 1\n",
      "i=0, eval_set_loss = 2.4868240901095384\n",
      "i=10, eval_set_loss = 2.420073820266856\n",
      "i=20, eval_set_loss = 2.3667579878014475\n",
      "i=30, eval_set_loss = 2.324221746644366\n",
      "i=40, eval_set_loss = 2.2904008819869826\n",
      "i=50, eval_set_loss = 2.2635650059965866\n",
      "i=60, eval_set_loss = 2.2422024652206494\n",
      "i=70, eval_set_loss = 2.2253027152781777\n",
      "i=80, eval_set_loss = 2.212141339686136\n",
      "i=90, eval_set_loss = 2.201640369898524\n",
      "i=100, eval_set_loss = 2.1926508438556813\n",
      "i=110, eval_set_loss = 2.1854244403876857\n",
      "i=120, eval_set_loss = 2.1796804465349755\n",
      "i=130, eval_set_loss = 2.1750018446434862\n",
      "i=140, eval_set_loss = 2.1710531228856\n",
      "i=150, eval_set_loss = 2.1676784216113196\n",
      "i=160, eval_set_loss = 2.164629428059997\n",
      "i=170, eval_set_loss = 2.162231513157391\n",
      "i=180, eval_set_loss = 2.1600761833938624\n",
      "i=190, eval_set_loss = 2.1582860980803735\n",
      "i=200, eval_set_loss = 2.156682401986646\n",
      "i=210, eval_set_loss = 2.1555182619598767\n",
      "i=220, eval_set_loss = 2.1544181224567738\n",
      "i=230, eval_set_loss = 2.15325258727323\n",
      "i=240, eval_set_loss = 2.1523739630791523\n",
      "i=250, eval_set_loss = 2.151618216005988\n",
      "i=260, eval_set_loss = 2.1508506519672705\n",
      "i=270, eval_set_loss = 2.1502566628825486\n",
      "i=280, eval_set_loss = 2.149885630120708\n",
      "i=290, eval_set_loss = 2.149411507570564\n",
      "i=300, eval_set_loss = 2.1491718057412927\n",
      "i=310, eval_set_loss = 2.149006507303973\n",
      "i=320, eval_set_loss = 2.1488075206942265\n",
      "i=330, eval_set_loss = 2.1489672009830834\n",
      "Stopping early: curr_loss of 2.1489672009830834\n",
      "                                        exceeds compare_loss of 2.1488075206942265\n",
      "Singleton weight = 0.1\n",
      "trial_number = 1\n",
      "i=0, eval_set_loss = 2.4868240901095384\n",
      "i=10, eval_set_loss = 2.4038239555355303\n",
      "i=20, eval_set_loss = 2.34249776327777\n",
      "i=30, eval_set_loss = 2.2967643092008285\n",
      "i=40, eval_set_loss = 2.262261669792062\n",
      "i=50, eval_set_loss = 2.2367933706736514\n",
      "i=60, eval_set_loss = 2.217487712864595\n",
      "i=70, eval_set_loss = 2.2026960290787487\n",
      "i=80, eval_set_loss = 2.191015077648881\n",
      "i=90, eval_set_loss = 2.181754023210576\n",
      "i=100, eval_set_loss = 2.1739137474304564\n",
      "i=110, eval_set_loss = 2.1678079405469113\n",
      "i=120, eval_set_loss = 2.1633436826959014\n",
      "i=130, eval_set_loss = 2.1601093931036583\n",
      "i=140, eval_set_loss = 2.157264699488203\n",
      "i=150, eval_set_loss = 2.154984401879135\n",
      "i=160, eval_set_loss = 2.1531665689776904\n",
      "i=170, eval_set_loss = 2.151616281330179\n",
      "i=180, eval_set_loss = 2.1504244437629705\n",
      "i=190, eval_set_loss = 2.1497386838088977\n",
      "i=200, eval_set_loss = 2.149015651377709\n",
      "i=210, eval_set_loss = 2.148578153225045\n",
      "i=220, eval_set_loss = 2.148033037920499\n",
      "i=230, eval_set_loss = 2.1475432518427393\n",
      "i=240, eval_set_loss = 2.147236728596322\n",
      "i=250, eval_set_loss = 2.146818305446315\n",
      "i=260, eval_set_loss = 2.1463740950571535\n",
      "i=270, eval_set_loss = 2.146312326479234\n",
      "i=280, eval_set_loss = 2.146027101008599\n",
      "i=290, eval_set_loss = 2.145879783319802\n",
      "i=300, eval_set_loss = 2.1457637503381424\n",
      "i=310, eval_set_loss = 2.145869659669359\n",
      "Stopping early: curr_loss of 2.145869659669359\n",
      "                                        exceeds compare_loss of 2.1457637503381424\n",
      "Singleton weight = 0.2\n",
      "trial_number = 1\n",
      "i=0, eval_set_loss = 2.4868240901095384\n",
      "i=10, eval_set_loss = 2.402911830936626\n",
      "i=20, eval_set_loss = 2.341432190028308\n",
      "i=30, eval_set_loss = 2.2956527053977585\n",
      "i=40, eval_set_loss = 2.2611723683504925\n",
      "i=50, eval_set_loss = 2.235830267124013\n",
      "i=60, eval_set_loss = 2.216277835215269\n",
      "i=70, eval_set_loss = 2.2013725679964713\n",
      "i=80, eval_set_loss = 2.1896586728762224\n",
      "i=90, eval_set_loss = 2.18058634364647\n",
      "i=100, eval_set_loss = 2.1732042702524166\n",
      "i=110, eval_set_loss = 2.1676993330886574\n",
      "i=120, eval_set_loss = 2.163188951251831\n",
      "i=130, eval_set_loss = 2.1595611330202145\n",
      "i=140, eval_set_loss = 2.156676442100541\n",
      "i=150, eval_set_loss = 2.1543285403524495\n",
      "i=160, eval_set_loss = 2.1522655168327534\n",
      "i=170, eval_set_loss = 2.1507607502583377\n",
      "i=180, eval_set_loss = 2.149501705578376\n",
      "i=190, eval_set_loss = 2.148734001372489\n",
      "i=200, eval_set_loss = 2.1480802964910675\n",
      "i=210, eval_set_loss = 2.147837273191996\n",
      "i=220, eval_set_loss = 2.147306821037209\n",
      "i=230, eval_set_loss = 2.1466647390202187\n",
      "i=240, eval_set_loss = 2.1462894527683494\n",
      "i=250, eval_set_loss = 2.1461866517611368\n",
      "i=260, eval_set_loss = 2.146018349674106\n",
      "i=270, eval_set_loss = 2.1458774491907677\n",
      "i=280, eval_set_loss = 2.145671434280941\n",
      "i=290, eval_set_loss = 2.145862776721631\n",
      "Stopping early: curr_loss of 2.145862776721631\n",
      "                                        exceeds compare_loss of 2.145671434280941\n",
      "Singleton weight = 0.3\n",
      "trial_number = 1\n",
      "i=0, eval_set_loss = 2.4868240901095384\n",
      "i=10, eval_set_loss = 2.401792047471361\n",
      "i=20, eval_set_loss = 2.3398970971819417\n",
      "i=30, eval_set_loss = 2.294402387075568\n",
      "i=40, eval_set_loss = 2.260315632803239\n",
      "i=50, eval_set_loss = 2.2350113295321394\n",
      "i=60, eval_set_loss = 2.2153518794692855\n",
      "i=70, eval_set_loss = 2.200432220866951\n",
      "i=80, eval_set_loss = 2.1886858528242565\n",
      "i=90, eval_set_loss = 2.1795687205799985\n",
      "i=100, eval_set_loss = 2.1725346984373717\n",
      "i=110, eval_set_loss = 2.1663815990220043\n",
      "i=120, eval_set_loss = 2.161903233357754\n",
      "i=130, eval_set_loss = 2.1583188463878074\n",
      "i=140, eval_set_loss = 2.1556825891874523\n",
      "i=150, eval_set_loss = 2.1533432304722147\n",
      "i=160, eval_set_loss = 2.151595617692627\n",
      "i=170, eval_set_loss = 2.150124318641865\n",
      "i=180, eval_set_loss = 2.148810971526835\n",
      "i=190, eval_set_loss = 2.1480166806679577\n",
      "i=200, eval_set_loss = 2.1474797834209522\n",
      "i=210, eval_set_loss = 2.146885825694088\n",
      "i=220, eval_set_loss = 2.1463399227793913\n",
      "i=230, eval_set_loss = 2.1456681174693633\n",
      "i=240, eval_set_loss = 2.1452894136551977\n",
      "i=250, eval_set_loss = 2.145153856496301\n",
      "i=260, eval_set_loss = 2.1449321644855495\n",
      "i=270, eval_set_loss = 2.1448547021764863\n",
      "i=280, eval_set_loss = 2.144736636736159\n",
      "i=290, eval_set_loss = 2.144743655801289\n",
      "Stopping early: curr_loss of 2.144743655801289\n",
      "                                        exceeds compare_loss of 2.144736636736159\n",
      "Singleton weight = 0.4\n",
      "trial_number = 1\n",
      "i=0, eval_set_loss = 2.4868240901095384\n",
      "i=10, eval_set_loss = 2.4006121517383128\n",
      "i=20, eval_set_loss = 2.3386053947732157\n",
      "i=30, eval_set_loss = 2.2927163404367144\n",
      "i=40, eval_set_loss = 2.258559000409294\n",
      "i=50, eval_set_loss = 2.233377212208686\n",
      "i=60, eval_set_loss = 2.21392325427554\n",
      "i=70, eval_set_loss = 2.1993605169063146\n",
      "i=80, eval_set_loss = 2.187830451003291\n",
      "i=90, eval_set_loss = 2.1789183462420993\n",
      "i=100, eval_set_loss = 2.172059355045693\n",
      "i=110, eval_set_loss = 2.1666283194812874\n",
      "i=120, eval_set_loss = 2.1622195843180316\n",
      "i=130, eval_set_loss = 2.158825662724128\n",
      "i=140, eval_set_loss = 2.1560502255786567\n",
      "i=150, eval_set_loss = 2.1538410650168736\n",
      "i=160, eval_set_loss = 2.1521067731895265\n",
      "i=170, eval_set_loss = 2.1507811274232473\n",
      "i=180, eval_set_loss = 2.149796721485715\n",
      "i=190, eval_set_loss = 2.1489608362225496\n",
      "i=200, eval_set_loss = 2.1484556275550584\n",
      "i=210, eval_set_loss = 2.1480947784340203\n",
      "i=220, eval_set_loss = 2.1476294939823593\n",
      "i=230, eval_set_loss = 2.147034932175182\n",
      "i=240, eval_set_loss = 2.1468617706262263\n",
      "i=250, eval_set_loss = 2.146778397087814\n",
      "i=260, eval_set_loss = 2.1463962160484424\n",
      "i=270, eval_set_loss = 2.1461945052200617\n",
      "i=280, eval_set_loss = 2.1460655853192545\n",
      "i=290, eval_set_loss = 2.1461396091313336\n",
      "Stopping early: curr_loss of 2.1461396091313336\n",
      "                                        exceeds compare_loss of 2.1460655853192545\n",
      "Singleton weight = 0.5\n",
      "trial_number = 1\n",
      "i=0, eval_set_loss = 2.4868240901095384\n",
      "i=10, eval_set_loss = 2.399424235886115\n",
      "i=20, eval_set_loss = 2.336826562129595\n",
      "i=30, eval_set_loss = 2.291097751016879\n",
      "i=40, eval_set_loss = 2.2575391424293865\n",
      "i=50, eval_set_loss = 2.232246041285312\n",
      "i=60, eval_set_loss = 2.213326820858884\n",
      "i=70, eval_set_loss = 2.1987798810361587\n",
      "i=80, eval_set_loss = 2.1874547754184883\n",
      "i=90, eval_set_loss = 2.178327676128084\n",
      "i=100, eval_set_loss = 2.1713074670209664\n",
      "i=110, eval_set_loss = 2.1658047558205884\n",
      "i=120, eval_set_loss = 2.16199998770277\n",
      "i=130, eval_set_loss = 2.158739137882203\n",
      "i=140, eval_set_loss = 2.156267241869818\n",
      "i=150, eval_set_loss = 2.1542525565113944\n",
      "i=160, eval_set_loss = 2.1526465983911343\n",
      "i=170, eval_set_loss = 2.1513666276626413\n",
      "i=180, eval_set_loss = 2.150187768969663\n",
      "i=190, eval_set_loss = 2.1494663214617566\n",
      "i=200, eval_set_loss = 2.148889999179028\n",
      "i=210, eval_set_loss = 2.1486264849010035\n",
      "i=220, eval_set_loss = 2.148169781926911\n",
      "i=230, eval_set_loss = 2.1475692540286095\n",
      "i=240, eval_set_loss = 2.1474248964624896\n",
      "i=250, eval_set_loss = 2.1475008735043635\n",
      "Stopping early: curr_loss of 2.1475008735043635\n",
      "                                        exceeds compare_loss of 2.1474248964624896\n",
      "Singleton weight = 0.6\n",
      "trial_number = 1\n",
      "i=0, eval_set_loss = 2.4868240901095384\n",
      "i=10, eval_set_loss = 2.3977846508959972\n",
      "i=20, eval_set_loss = 2.334483917760525\n",
      "i=30, eval_set_loss = 2.288924778410166\n",
      "i=40, eval_set_loss = 2.255273636954199\n",
      "i=50, eval_set_loss = 2.2305184787603785\n",
      "i=60, eval_set_loss = 2.211497992766621\n",
      "i=70, eval_set_loss = 2.197235344768463\n",
      "i=80, eval_set_loss = 2.186135311284096\n",
      "i=90, eval_set_loss = 2.1777277052282336\n",
      "i=100, eval_set_loss = 2.170713246841334\n",
      "i=110, eval_set_loss = 2.165416448879177\n",
      "i=120, eval_set_loss = 2.1613319714350427\n",
      "i=130, eval_set_loss = 2.158300207147234\n",
      "i=140, eval_set_loss = 2.1556893799081265\n",
      "i=150, eval_set_loss = 2.153394086079219\n",
      "i=160, eval_set_loss = 2.1515952195318198\n",
      "i=170, eval_set_loss = 2.150225442160516\n",
      "i=180, eval_set_loss = 2.1490616334108794\n",
      "i=190, eval_set_loss = 2.148305303148041\n",
      "i=200, eval_set_loss = 2.1477374632129775\n",
      "i=210, eval_set_loss = 2.147522168094074\n",
      "i=220, eval_set_loss = 2.147318561791786\n",
      "i=230, eval_set_loss = 2.1467339837263664\n",
      "i=240, eval_set_loss = 2.146236645133011\n",
      "i=250, eval_set_loss = 2.1461282937821697\n",
      "i=260, eval_set_loss = 2.1460629788401495\n",
      "i=270, eval_set_loss = 2.146246236819895\n",
      "Stopping early: curr_loss of 2.146246236819895\n",
      "                                        exceeds compare_loss of 2.1460629788401495\n",
      "Singleton weight = 0.7\n",
      "trial_number = 1\n",
      "i=0, eval_set_loss = 2.4868240901095384\n",
      "i=10, eval_set_loss = 2.395983156680424\n",
      "i=20, eval_set_loss = 2.332332883802392\n",
      "i=30, eval_set_loss = 2.286832573056647\n",
      "i=40, eval_set_loss = 2.2533438507821755\n",
      "i=50, eval_set_loss = 2.2288868004678357\n",
      "i=60, eval_set_loss = 2.2102017455731673\n",
      "i=70, eval_set_loss = 2.196143736400847\n",
      "i=80, eval_set_loss = 2.185063785633264\n",
      "i=90, eval_set_loss = 2.1768541112870516\n",
      "i=100, eval_set_loss = 2.170374917730726\n",
      "i=110, eval_set_loss = 2.164771041114265\n",
      "i=120, eval_set_loss = 2.160948116679801\n",
      "i=130, eval_set_loss = 2.157931200950076\n",
      "i=140, eval_set_loss = 2.1556822576773906\n",
      "i=150, eval_set_loss = 2.153662510492426\n",
      "i=160, eval_set_loss = 2.1523073168990003\n",
      "i=170, eval_set_loss = 2.1514073317699056\n",
      "i=180, eval_set_loss = 2.1502198316341636\n",
      "i=190, eval_set_loss = 2.1492487881529017\n",
      "i=200, eval_set_loss = 2.1487806247610117\n",
      "i=210, eval_set_loss = 2.1484347435157076\n",
      "i=220, eval_set_loss = 2.1481119058274833\n",
      "i=230, eval_set_loss = 2.1481212904026274\n",
      "Stopping early: curr_loss of 2.1481212904026274\n",
      "                                        exceeds compare_loss of 2.1481119058274833\n",
      "Singleton weight = 0.8\n",
      "trial_number = 1\n",
      "i=0, eval_set_loss = 2.4868240901095384\n",
      "i=10, eval_set_loss = 2.393681309723911\n",
      "i=20, eval_set_loss = 2.3292193483715846\n",
      "i=30, eval_set_loss = 2.2837970953574236\n",
      "i=40, eval_set_loss = 2.251067939706285\n",
      "i=50, eval_set_loss = 2.2266335052867596\n",
      "i=60, eval_set_loss = 2.2084793284201734\n",
      "i=70, eval_set_loss = 2.1945801007419368\n",
      "i=80, eval_set_loss = 2.184057284368789\n",
      "i=90, eval_set_loss = 2.175703368597436\n",
      "i=100, eval_set_loss = 2.1690817558589814\n",
      "i=110, eval_set_loss = 2.163947244864903\n",
      "i=120, eval_set_loss = 2.1599385137409475\n",
      "i=130, eval_set_loss = 2.156857944407882\n",
      "i=140, eval_set_loss = 2.1545722475349245\n",
      "i=150, eval_set_loss = 2.1528226900447023\n",
      "i=160, eval_set_loss = 2.1516227569893114\n",
      "i=170, eval_set_loss = 2.150577047230657\n",
      "i=180, eval_set_loss = 2.1497268472242776\n",
      "i=190, eval_set_loss = 2.1490169059445274\n",
      "i=200, eval_set_loss = 2.1486543503008306\n",
      "i=210, eval_set_loss = 2.1481250138530275\n",
      "i=220, eval_set_loss = 2.148012140338261\n",
      "i=230, eval_set_loss = 2.1477374898000474\n",
      "i=240, eval_set_loss = 2.147592554265018\n",
      "i=250, eval_set_loss = 2.1477257465445216\n",
      "Stopping early: curr_loss of 2.1477257465445216\n",
      "                                        exceeds compare_loss of 2.147592554265018\n",
      "Singleton weight = 0.9\n",
      "trial_number = 1\n",
      "i=0, eval_set_loss = 2.4868240901095384\n",
      "i=10, eval_set_loss = 2.391293801772189\n",
      "i=20, eval_set_loss = 2.3273323104833676\n",
      "i=30, eval_set_loss = 2.2820570433646075\n",
      "i=40, eval_set_loss = 2.248933916274761\n",
      "i=50, eval_set_loss = 2.2246948430699023\n",
      "i=60, eval_set_loss = 2.206743969605373\n",
      "i=70, eval_set_loss = 2.1931670629227016\n",
      "i=80, eval_set_loss = 2.182797712379799\n",
      "i=90, eval_set_loss = 2.174741909840259\n",
      "i=100, eval_set_loss = 2.1686792436096702\n",
      "i=110, eval_set_loss = 2.1637881386739135\n",
      "i=120, eval_set_loss = 2.1601921759691622\n",
      "i=130, eval_set_loss = 2.1574637504441263\n",
      "i=140, eval_set_loss = 2.155249808723459\n",
      "i=150, eval_set_loss = 2.153505555200031\n",
      "i=160, eval_set_loss = 2.1524668502162956\n",
      "i=170, eval_set_loss = 2.1513369850491237\n",
      "i=180, eval_set_loss = 2.1501647954211642\n",
      "i=190, eval_set_loss = 2.1497142982864332\n",
      "i=200, eval_set_loss = 2.1492839826744734\n",
      "i=210, eval_set_loss = 2.149101738381855\n",
      "i=220, eval_set_loss = 2.148617626875771\n",
      "i=230, eval_set_loss = 2.1484352317879667\n",
      "i=240, eval_set_loss = 2.1484779231762796\n",
      "Stopping early: curr_loss of 2.1484779231762796\n",
      "                                        exceeds compare_loss of 2.1484352317879667\n",
      "Singleton weight = 1.0\n",
      "trial_number = 1\n",
      "i=0, eval_set_loss = 2.4868240901095384\n",
      "i=10, eval_set_loss = 2.388270434436201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/xr46tkk15h10554_3mptdjlw0000gn/T/ipykernel_16166/2983974394.py:30: UserWarning: Some weights are not positive - may cause unexpected results\n",
      "  stb_tmp = stb.StructureBoostMulti(num_trees=2000, feature_configs=fc1, num_classes=12, target_structure=ts, learning_rate=.02)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=20, eval_set_loss = 2.3232981971284694\n",
      "i=30, eval_set_loss = 2.2782777858362353\n",
      "i=40, eval_set_loss = 2.2457566539800817\n",
      "i=50, eval_set_loss = 2.2221207663856783\n",
      "i=60, eval_set_loss = 2.2042795781246167\n",
      "i=70, eval_set_loss = 2.1908833996048154\n",
      "i=80, eval_set_loss = 2.1809097051458295\n",
      "i=90, eval_set_loss = 2.17333894727841\n",
      "i=100, eval_set_loss = 2.1670336890753443\n",
      "i=110, eval_set_loss = 2.1625150102158366\n",
      "i=120, eval_set_loss = 2.1590443564148547\n",
      "i=130, eval_set_loss = 2.1565965955406488\n",
      "i=140, eval_set_loss = 2.154655264159604\n",
      "i=150, eval_set_loss = 2.1530852542245698\n",
      "i=160, eval_set_loss = 2.152107697586679\n",
      "i=170, eval_set_loss = 2.151306196589801\n",
      "i=180, eval_set_loss = 2.150742999830675\n",
      "i=190, eval_set_loss = 2.15027408031081\n",
      "i=200, eval_set_loss = 2.149727886490246\n",
      "i=210, eval_set_loss = 2.1495058536040297\n",
      "i=220, eval_set_loss = 2.1492465159334992\n",
      "i=230, eval_set_loss = 2.1491148481902043\n",
      "i=240, eval_set_loss = 2.149293475342171\n",
      "Stopping early: curr_loss of 2.149293475342171\n",
      "                                        exceeds compare_loss of 2.1491148481902043\n",
      "Singleton weight = 0.0\n",
      "trial_number = 2\n",
      "i=0, eval_set_loss = 2.484582147812842\n",
      "i=10, eval_set_loss = 2.4163597899280767\n",
      "i=20, eval_set_loss = 2.3629657805215136\n",
      "i=30, eval_set_loss = 2.3208391231401273\n",
      "i=40, eval_set_loss = 2.287738170572318\n",
      "i=50, eval_set_loss = 2.2618527277260974\n",
      "i=60, eval_set_loss = 2.2417387307680094\n",
      "i=70, eval_set_loss = 2.225681574500191\n",
      "i=80, eval_set_loss = 2.213145011906621\n",
      "i=90, eval_set_loss = 2.203167467173107\n",
      "i=100, eval_set_loss = 2.195351645696615\n",
      "i=110, eval_set_loss = 2.1887361932768123\n",
      "i=120, eval_set_loss = 2.1834861958845875\n",
      "i=130, eval_set_loss = 2.179175404461643\n",
      "i=140, eval_set_loss = 2.175521631865582\n",
      "i=150, eval_set_loss = 2.172605954067708\n",
      "i=160, eval_set_loss = 2.169965853184831\n",
      "i=170, eval_set_loss = 2.167700905729949\n",
      "i=180, eval_set_loss = 2.165892383226268\n",
      "i=190, eval_set_loss = 2.1642827160357143\n",
      "i=200, eval_set_loss = 2.162666880917664\n",
      "i=210, eval_set_loss = 2.161537288666088\n",
      "i=220, eval_set_loss = 2.1620265812814767\n",
      "Stopping early: curr_loss of 2.1620265812814767\n",
      "                                        exceeds compare_loss of 2.161537288666088\n",
      "Singleton weight = 0.1\n",
      "trial_number = 2\n",
      "i=0, eval_set_loss = 2.484582147812842\n",
      "i=10, eval_set_loss = 2.401598415157304\n",
      "i=20, eval_set_loss = 2.341405631107135\n",
      "i=30, eval_set_loss = 2.2963996599635217\n",
      "i=40, eval_set_loss = 2.263280270315076\n",
      "i=50, eval_set_loss = 2.238224715839967\n",
      "i=60, eval_set_loss = 2.2191664333167167\n",
      "i=70, eval_set_loss = 2.2045361477984295\n",
      "i=80, eval_set_loss = 2.193778806082543\n",
      "i=90, eval_set_loss = 2.1854538815937876\n",
      "i=100, eval_set_loss = 2.178551587095617\n",
      "i=110, eval_set_loss = 2.1733774753506725\n",
      "i=120, eval_set_loss = 2.1695119306645414\n",
      "i=130, eval_set_loss = 2.16633930884416\n",
      "i=140, eval_set_loss = 2.163754682139948\n",
      "i=150, eval_set_loss = 2.161849181434888\n",
      "i=160, eval_set_loss = 2.160276049143989\n",
      "i=170, eval_set_loss = 2.1591804982574154\n",
      "i=180, eval_set_loss = 2.157792557819032\n",
      "i=190, eval_set_loss = 2.1570491699509344\n",
      "i=200, eval_set_loss = 2.156175629159132\n",
      "i=210, eval_set_loss = 2.155642250077758\n",
      "i=220, eval_set_loss = 2.155191550617711\n",
      "i=230, eval_set_loss = 2.1546695155498092\n",
      "i=240, eval_set_loss = 2.1545181283270805\n",
      "i=250, eval_set_loss = 2.1545731694145016\n",
      "Stopping early: curr_loss of 2.1545731694145016\n",
      "                                        exceeds compare_loss of 2.1545181283270805\n",
      "Singleton weight = 0.2\n",
      "trial_number = 2\n",
      "i=0, eval_set_loss = 2.484582147812842\n",
      "i=10, eval_set_loss = 2.4006595487613476\n",
      "i=20, eval_set_loss = 2.340176932169781\n",
      "i=30, eval_set_loss = 2.2953133906414127\n",
      "i=40, eval_set_loss = 2.2622172071135394\n",
      "i=50, eval_set_loss = 2.237128239108366\n",
      "i=60, eval_set_loss = 2.218544140983988\n",
      "i=70, eval_set_loss = 2.203804187725643\n",
      "i=80, eval_set_loss = 2.1927496582818127\n",
      "i=90, eval_set_loss = 2.184651028344741\n",
      "i=100, eval_set_loss = 2.178227913711968\n",
      "i=110, eval_set_loss = 2.1731384083483443\n",
      "i=120, eval_set_loss = 2.169200550189036\n",
      "i=130, eval_set_loss = 2.166283656423307\n",
      "i=140, eval_set_loss = 2.163531542346961\n",
      "i=150, eval_set_loss = 2.161573057444847\n",
      "i=160, eval_set_loss = 2.1599103879354544\n",
      "i=170, eval_set_loss = 2.1587457336187743\n",
      "i=180, eval_set_loss = 2.157545636146019\n",
      "i=190, eval_set_loss = 2.156271271256786\n",
      "i=200, eval_set_loss = 2.1555301986643687\n",
      "i=210, eval_set_loss = 2.1550397744289636\n",
      "i=220, eval_set_loss = 2.1545654284796756\n",
      "i=230, eval_set_loss = 2.15419669198776\n",
      "i=240, eval_set_loss = 2.154300620087983\n",
      "Stopping early: curr_loss of 2.154300620087983\n",
      "                                        exceeds compare_loss of 2.15419669198776\n",
      "Singleton weight = 0.3\n",
      "trial_number = 2\n",
      "i=0, eval_set_loss = 2.484582147812842\n",
      "i=10, eval_set_loss = 2.3997365269857203\n",
      "i=20, eval_set_loss = 2.3388296030470586\n",
      "i=30, eval_set_loss = 2.2939710769213764\n",
      "i=40, eval_set_loss = 2.2609666610783283\n",
      "i=50, eval_set_loss = 2.235975800087758\n",
      "i=60, eval_set_loss = 2.217268512797789\n",
      "i=70, eval_set_loss = 2.2029227486244873\n",
      "i=80, eval_set_loss = 2.1921891465349783\n",
      "i=90, eval_set_loss = 2.1839628032352123\n",
      "i=100, eval_set_loss = 2.1774704907170883\n",
      "i=110, eval_set_loss = 2.172347113356992\n",
      "i=120, eval_set_loss = 2.1684662496281324\n",
      "i=130, eval_set_loss = 2.165628156558626\n",
      "i=140, eval_set_loss = 2.162837560514604\n",
      "i=150, eval_set_loss = 2.1610724028140305\n",
      "i=160, eval_set_loss = 2.159179722879506\n",
      "i=170, eval_set_loss = 2.157988220026642\n",
      "i=180, eval_set_loss = 2.156914331476321\n",
      "i=190, eval_set_loss = 2.1560956948490357\n",
      "i=200, eval_set_loss = 2.1553809866938525\n",
      "i=210, eval_set_loss = 2.1550112248348885\n",
      "i=220, eval_set_loss = 2.154490709267962\n",
      "i=230, eval_set_loss = 2.1540873257350657\n",
      "i=240, eval_set_loss = 2.1541267739115573\n",
      "Stopping early: curr_loss of 2.1541267739115573\n",
      "                                        exceeds compare_loss of 2.1540873257350657\n",
      "Singleton weight = 0.4\n",
      "trial_number = 2\n",
      "i=0, eval_set_loss = 2.484582147812842\n",
      "i=10, eval_set_loss = 2.3986617424577585\n",
      "i=20, eval_set_loss = 2.337452307073279\n",
      "i=30, eval_set_loss = 2.2925965879674655\n",
      "i=40, eval_set_loss = 2.2597550283914996\n",
      "i=50, eval_set_loss = 2.234808937990453\n",
      "i=60, eval_set_loss = 2.2162980060149655\n",
      "i=70, eval_set_loss = 2.202089170376577\n",
      "i=80, eval_set_loss = 2.1915636065471413\n",
      "i=90, eval_set_loss = 2.183730031539105\n",
      "i=100, eval_set_loss = 2.177484081943356\n",
      "i=110, eval_set_loss = 2.1726878271286463\n",
      "i=120, eval_set_loss = 2.1688683586681305\n",
      "i=130, eval_set_loss = 2.1659498982402305\n",
      "i=140, eval_set_loss = 2.163336710208834\n",
      "i=150, eval_set_loss = 2.161718520153135\n",
      "i=160, eval_set_loss = 2.160177116142782\n",
      "i=170, eval_set_loss = 2.1590295989057715\n",
      "i=180, eval_set_loss = 2.157832170757636\n",
      "i=190, eval_set_loss = 2.156958328357885\n",
      "i=200, eval_set_loss = 2.156304910978689\n",
      "i=210, eval_set_loss = 2.155775354379637\n",
      "i=220, eval_set_loss = 2.155290146956005\n",
      "i=230, eval_set_loss = 2.1547859214274467\n",
      "i=240, eval_set_loss = 2.154797476670306\n",
      "Stopping early: curr_loss of 2.154797476670306\n",
      "                                        exceeds compare_loss of 2.1547859214274467\n",
      "Singleton weight = 0.5\n",
      "trial_number = 2\n",
      "i=0, eval_set_loss = 2.484582147812842\n",
      "i=10, eval_set_loss = 2.3975488462271795\n",
      "i=20, eval_set_loss = 2.3358325819888552\n",
      "i=30, eval_set_loss = 2.290875386109518\n",
      "i=40, eval_set_loss = 2.25831966654434\n",
      "i=50, eval_set_loss = 2.233758832738647\n",
      "i=60, eval_set_loss = 2.2155732448000154\n",
      "i=70, eval_set_loss = 2.2013099101918123\n",
      "i=80, eval_set_loss = 2.1907611774813174\n",
      "i=90, eval_set_loss = 2.1830894418767164\n",
      "i=100, eval_set_loss = 2.1767657614478297\n",
      "i=110, eval_set_loss = 2.171974361676615\n",
      "i=120, eval_set_loss = 2.1683843435504038\n",
      "i=130, eval_set_loss = 2.1656413793228517\n",
      "i=140, eval_set_loss = 2.1632205140227487\n",
      "i=150, eval_set_loss = 2.1614869522162956\n",
      "i=160, eval_set_loss = 2.1597001298230816\n",
      "i=170, eval_set_loss = 2.1587426350989887\n",
      "i=180, eval_set_loss = 2.157661236396487\n",
      "i=190, eval_set_loss = 2.156825958630143\n",
      "i=200, eval_set_loss = 2.156187415592051\n",
      "i=210, eval_set_loss = 2.1559669556262344\n",
      "i=220, eval_set_loss = 2.1555321441157647\n",
      "i=230, eval_set_loss = 2.1553796018319566\n",
      "i=240, eval_set_loss = 2.1553024605357147\n",
      "i=250, eval_set_loss = 2.1552118600434023\n",
      "i=260, eval_set_loss = 2.154971217077923\n",
      "i=270, eval_set_loss = 2.1549655218562345\n",
      "i=280, eval_set_loss = 2.1549462216650923\n",
      "i=290, eval_set_loss = 2.154953991654332\n",
      "Stopping early: curr_loss of 2.154953991654332\n",
      "                                        exceeds compare_loss of 2.1549462216650923\n",
      "Singleton weight = 0.6\n",
      "trial_number = 2\n",
      "i=0, eval_set_loss = 2.484582147812842\n",
      "i=10, eval_set_loss = 2.3962220353362533\n",
      "i=20, eval_set_loss = 2.334103812972509\n",
      "i=30, eval_set_loss = 2.2891017043368374\n",
      "i=40, eval_set_loss = 2.2565928746154555\n",
      "i=50, eval_set_loss = 2.2321086782751083\n",
      "i=60, eval_set_loss = 2.214510268903914\n",
      "i=70, eval_set_loss = 2.200613803334143\n",
      "i=80, eval_set_loss = 2.1903387950800055\n",
      "i=90, eval_set_loss = 2.1826467304296604\n",
      "i=100, eval_set_loss = 2.176534669813356\n",
      "i=110, eval_set_loss = 2.1721012564558424\n",
      "i=120, eval_set_loss = 2.1686837151012117\n",
      "i=130, eval_set_loss = 2.16604935658099\n",
      "i=140, eval_set_loss = 2.1635304290252386\n",
      "i=150, eval_set_loss = 2.161863142770724\n",
      "i=160, eval_set_loss = 2.1605983453308766\n",
      "i=170, eval_set_loss = 2.15938852408095\n",
      "i=180, eval_set_loss = 2.158153215422135\n",
      "i=190, eval_set_loss = 2.157238731878312\n",
      "i=200, eval_set_loss = 2.1566357957753577\n",
      "i=210, eval_set_loss = 2.1562448150001945\n",
      "i=220, eval_set_loss = 2.1559504683775814\n",
      "i=230, eval_set_loss = 2.155455600016128\n",
      "i=240, eval_set_loss = 2.1551052633676795\n",
      "i=250, eval_set_loss = 2.154942935771293\n",
      "i=260, eval_set_loss = 2.1548421012996695\n",
      "i=270, eval_set_loss = 2.1548872127235765\n",
      "Stopping early: curr_loss of 2.1548872127235765\n",
      "                                        exceeds compare_loss of 2.1548421012996695\n",
      "Singleton weight = 0.7\n",
      "trial_number = 2\n",
      "i=0, eval_set_loss = 2.484582147812842\n",
      "i=10, eval_set_loss = 2.394467791770733\n",
      "i=20, eval_set_loss = 2.3317311819074735\n",
      "i=30, eval_set_loss = 2.2872709911353524\n",
      "i=40, eval_set_loss = 2.2545859954829\n",
      "i=50, eval_set_loss = 2.230563243472218\n",
      "i=60, eval_set_loss = 2.212581912977329\n",
      "i=70, eval_set_loss = 2.1985177153611954\n",
      "i=80, eval_set_loss = 2.188240793851896\n",
      "i=90, eval_set_loss = 2.1807930799302575\n",
      "i=100, eval_set_loss = 2.1748107729008823\n",
      "i=110, eval_set_loss = 2.170370191532284\n",
      "i=120, eval_set_loss = 2.1673379632363874\n",
      "i=130, eval_set_loss = 2.164955670466696\n",
      "i=140, eval_set_loss = 2.1625506096432296\n",
      "i=150, eval_set_loss = 2.1610495847175413\n",
      "i=160, eval_set_loss = 2.1595389991757927\n",
      "i=170, eval_set_loss = 2.158657342712672\n",
      "i=180, eval_set_loss = 2.1577919680457844\n",
      "i=190, eval_set_loss = 2.15684696366985\n",
      "i=200, eval_set_loss = 2.1562937960779096\n",
      "i=210, eval_set_loss = 2.1560678530827064\n",
      "i=220, eval_set_loss = 2.1558547869179754\n",
      "i=230, eval_set_loss = 2.155326625352983\n",
      "i=240, eval_set_loss = 2.1553292414144236\n",
      "Stopping early: curr_loss of 2.1553292414144236\n",
      "                                        exceeds compare_loss of 2.155326625352983\n",
      "Singleton weight = 0.8\n",
      "trial_number = 2\n",
      "i=0, eval_set_loss = 2.484582147812842\n",
      "i=10, eval_set_loss = 2.3925137034800428\n",
      "i=20, eval_set_loss = 2.3293914709287606\n",
      "i=30, eval_set_loss = 2.28444171183686\n",
      "i=40, eval_set_loss = 2.2522686163192978\n",
      "i=50, eval_set_loss = 2.228000725133701\n",
      "i=60, eval_set_loss = 2.2104355941786182\n",
      "i=70, eval_set_loss = 2.1971032878250187\n",
      "i=80, eval_set_loss = 2.1870549735765636\n",
      "i=90, eval_set_loss = 2.180160248544363\n",
      "i=100, eval_set_loss = 2.1748495181650296\n",
      "i=110, eval_set_loss = 2.1704563940838124\n",
      "i=120, eval_set_loss = 2.1675734874775103\n",
      "i=130, eval_set_loss = 2.1651747229626577\n",
      "i=140, eval_set_loss = 2.1628112362244725\n",
      "i=150, eval_set_loss = 2.161765383188732\n",
      "i=160, eval_set_loss = 2.160687201454824\n",
      "i=170, eval_set_loss = 2.1601697459978206\n",
      "i=180, eval_set_loss = 2.159461442649724\n",
      "i=190, eval_set_loss = 2.1585931416142308\n",
      "i=200, eval_set_loss = 2.1579819745618543\n",
      "i=210, eval_set_loss = 2.1577017260686144\n",
      "i=220, eval_set_loss = 2.157527169808039\n",
      "i=230, eval_set_loss = 2.1571855689931256\n",
      "i=240, eval_set_loss = 2.156968295200709\n",
      "i=250, eval_set_loss = 2.15711487534779\n",
      "Stopping early: curr_loss of 2.15711487534779\n",
      "                                        exceeds compare_loss of 2.156968295200709\n",
      "Singleton weight = 0.9\n",
      "trial_number = 2\n",
      "i=0, eval_set_loss = 2.484582147812842\n",
      "i=10, eval_set_loss = 2.3902163244740953\n",
      "i=20, eval_set_loss = 2.3268765357172136\n",
      "i=30, eval_set_loss = 2.281926033029639\n",
      "i=40, eval_set_loss = 2.2500806913004796\n",
      "i=50, eval_set_loss = 2.2261242033289377\n",
      "i=60, eval_set_loss = 2.208978086927342\n",
      "i=70, eval_set_loss = 2.1965822997393474\n",
      "i=80, eval_set_loss = 2.1870094909812856\n",
      "i=90, eval_set_loss = 2.180095865194018\n",
      "i=100, eval_set_loss = 2.1750671777541846\n",
      "i=110, eval_set_loss = 2.170605928574656\n",
      "i=120, eval_set_loss = 2.1677317490715753\n",
      "i=130, eval_set_loss = 2.1653939707970142\n",
      "i=140, eval_set_loss = 2.1632035289186335\n",
      "i=150, eval_set_loss = 2.161719930894533\n",
      "i=160, eval_set_loss = 2.1604255892145114\n",
      "i=170, eval_set_loss = 2.160033211199337\n",
      "i=180, eval_set_loss = 2.159525283959385\n",
      "i=190, eval_set_loss = 2.158804211963719\n",
      "i=200, eval_set_loss = 2.158380468623302\n",
      "i=210, eval_set_loss = 2.158125986488148\n",
      "i=220, eval_set_loss = 2.158033537200748\n",
      "i=230, eval_set_loss = 2.157859530210579\n",
      "i=240, eval_set_loss = 2.157866826723985\n",
      "Stopping early: curr_loss of 2.157866826723985\n",
      "                                        exceeds compare_loss of 2.157859530210579\n",
      "Singleton weight = 1.0\n",
      "trial_number = 2\n",
      "i=0, eval_set_loss = 2.484582147812842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/xr46tkk15h10554_3mptdjlw0000gn/T/ipykernel_16166/2983974394.py:30: UserWarning: Some weights are not positive - may cause unexpected results\n",
      "  stb_tmp = stb.StructureBoostMulti(num_trees=2000, feature_configs=fc1, num_classes=12, target_structure=ts, learning_rate=.02)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=10, eval_set_loss = 2.388102636170585\n",
      "i=20, eval_set_loss = 2.3243897277380157\n",
      "i=30, eval_set_loss = 2.279638363913079\n",
      "i=40, eval_set_loss = 2.2483671944828707\n",
      "i=50, eval_set_loss = 2.224628841969624\n",
      "i=60, eval_set_loss = 2.207933918198442\n",
      "i=70, eval_set_loss = 2.194974107614038\n",
      "i=80, eval_set_loss = 2.185862573129055\n",
      "i=90, eval_set_loss = 2.1790717573347935\n",
      "i=100, eval_set_loss = 2.173900995357741\n",
      "i=110, eval_set_loss = 2.1699864927213124\n",
      "i=120, eval_set_loss = 2.167241818178608\n",
      "i=130, eval_set_loss = 2.165242800442544\n",
      "i=140, eval_set_loss = 2.16320235498588\n",
      "i=150, eval_set_loss = 2.1620288124926526\n",
      "i=160, eval_set_loss = 2.161030870075532\n",
      "i=170, eval_set_loss = 2.1603677651960678\n",
      "i=180, eval_set_loss = 2.159636658486862\n",
      "i=190, eval_set_loss = 2.1592423004031787\n",
      "i=200, eval_set_loss = 2.1589307593271037\n",
      "i=210, eval_set_loss = 2.1588412922964433\n",
      "i=220, eval_set_loss = 2.1588031412778568\n",
      "i=230, eval_set_loss = 2.15852068407571\n",
      "i=240, eval_set_loss = 2.15869698790245\n",
      "Stopping early: curr_loss of 2.15869698790245\n",
      "                                        exceeds compare_loss of 2.15852068407571\n",
      "Singleton weight = 0.0\n",
      "trial_number = 3\n",
      "i=0, eval_set_loss = 2.486129773506843\n",
      "i=10, eval_set_loss = 2.417820682483617\n",
      "i=20, eval_set_loss = 2.3628247585556355\n",
      "i=30, eval_set_loss = 2.3197530925850747\n",
      "i=40, eval_set_loss = 2.285985574577658\n",
      "i=50, eval_set_loss = 2.2593527325293477\n",
      "i=60, eval_set_loss = 2.2382575677094483\n",
      "i=70, eval_set_loss = 2.2218769707878594\n",
      "i=80, eval_set_loss = 2.208679027236576\n",
      "i=90, eval_set_loss = 2.1981784148839645\n",
      "i=100, eval_set_loss = 2.1896461683026502\n",
      "i=110, eval_set_loss = 2.1825723433820645\n",
      "i=120, eval_set_loss = 2.1769527487361726\n",
      "i=130, eval_set_loss = 2.1720809158918897\n",
      "i=140, eval_set_loss = 2.1679528797076593\n",
      "i=150, eval_set_loss = 2.1643999710406514\n",
      "i=160, eval_set_loss = 2.161298427779188\n",
      "i=170, eval_set_loss = 2.158656546789507\n",
      "i=180, eval_set_loss = 2.1561909460697555\n",
      "i=190, eval_set_loss = 2.154127224813195\n",
      "i=200, eval_set_loss = 2.152240355353635\n",
      "i=210, eval_set_loss = 2.1504137050272862\n",
      "i=220, eval_set_loss = 2.149141706712478\n",
      "i=230, eval_set_loss = 2.1477339659600396\n",
      "i=240, eval_set_loss = 2.1465326561877767\n",
      "i=250, eval_set_loss = 2.145554554884482\n",
      "i=260, eval_set_loss = 2.1448533719975376\n",
      "i=270, eval_set_loss = 2.1440438209083847\n",
      "i=280, eval_set_loss = 2.1431273601559564\n",
      "i=290, eval_set_loss = 2.142510283296447\n",
      "i=300, eval_set_loss = 2.141928836762637\n",
      "i=310, eval_set_loss = 2.141226621603797\n",
      "i=320, eval_set_loss = 2.1407891939741295\n",
      "i=330, eval_set_loss = 2.140134311120799\n",
      "i=340, eval_set_loss = 2.1400873948361236\n",
      "i=350, eval_set_loss = 2.139376945005444\n",
      "i=360, eval_set_loss = 2.138926351973221\n",
      "i=370, eval_set_loss = 2.1385504177992325\n",
      "i=380, eval_set_loss = 2.138210316379117\n",
      "i=390, eval_set_loss = 2.1379300942659194\n",
      "i=400, eval_set_loss = 2.1379138415645795\n",
      "i=410, eval_set_loss = 2.137764016793753\n",
      "i=420, eval_set_loss = 2.1374550027450794\n",
      "i=430, eval_set_loss = 2.1374188231696296\n",
      "i=440, eval_set_loss = 2.1371633767499105\n",
      "i=450, eval_set_loss = 2.1368816840311893\n",
      "i=460, eval_set_loss = 2.136673321548433\n",
      "i=470, eval_set_loss = 2.1366279667661616\n",
      "i=480, eval_set_loss = 2.1366130659299705\n",
      "i=490, eval_set_loss = 2.1363785753522198\n",
      "i=500, eval_set_loss = 2.1362476030485444\n",
      "i=510, eval_set_loss = 2.13612867117537\n",
      "i=520, eval_set_loss = 2.1359524029420247\n",
      "i=530, eval_set_loss = 2.135788952046236\n",
      "i=540, eval_set_loss = 2.1357957181937968\n",
      "Stopping early: curr_loss of 2.1357957181937968\n",
      "                                        exceeds compare_loss of 2.135788952046236\n",
      "Singleton weight = 0.1\n",
      "trial_number = 3\n",
      "i=0, eval_set_loss = 2.486129773506843\n",
      "i=10, eval_set_loss = 2.402031549527188\n",
      "i=20, eval_set_loss = 2.3391573636157874\n",
      "i=30, eval_set_loss = 2.2932622352032266\n",
      "i=40, eval_set_loss = 2.259004557514492\n",
      "i=50, eval_set_loss = 2.232856679051737\n",
      "i=60, eval_set_loss = 2.2131100839774134\n",
      "i=70, eval_set_loss = 2.197931357414068\n",
      "i=80, eval_set_loss = 2.186063705615317\n",
      "i=90, eval_set_loss = 2.1767429308946973\n",
      "i=100, eval_set_loss = 2.169104035880197\n",
      "i=110, eval_set_loss = 2.1630395933334463\n",
      "i=120, eval_set_loss = 2.1584058383419107\n",
      "i=130, eval_set_loss = 2.154812957225614\n",
      "i=140, eval_set_loss = 2.1515602124426807\n",
      "i=150, eval_set_loss = 2.1489502534217713\n",
      "i=160, eval_set_loss = 2.146885899080192\n",
      "i=170, eval_set_loss = 2.1450852138019028\n",
      "i=180, eval_set_loss = 2.1431208759383127\n",
      "i=190, eval_set_loss = 2.141828149140042\n",
      "i=200, eval_set_loss = 2.1406742849564093\n",
      "i=210, eval_set_loss = 2.1395827740830997\n",
      "i=220, eval_set_loss = 2.1389346593534646\n",
      "i=230, eval_set_loss = 2.1380727880079\n",
      "i=240, eval_set_loss = 2.13748018972335\n",
      "i=250, eval_set_loss = 2.136900892583214\n",
      "i=260, eval_set_loss = 2.136738165434652\n",
      "i=270, eval_set_loss = 2.136479594786189\n",
      "i=280, eval_set_loss = 2.1362872735916967\n",
      "i=290, eval_set_loss = 2.1358883383323763\n",
      "i=300, eval_set_loss = 2.135919358910272\n",
      "Stopping early: curr_loss of 2.135919358910272\n",
      "                                        exceeds compare_loss of 2.1358883383323763\n",
      "Singleton weight = 0.2\n",
      "trial_number = 3\n",
      "i=0, eval_set_loss = 2.486129773506843\n",
      "i=10, eval_set_loss = 2.401369517214864\n",
      "i=20, eval_set_loss = 2.33908793480522\n",
      "i=30, eval_set_loss = 2.2931166567779524\n",
      "i=40, eval_set_loss = 2.2584609273900007\n",
      "i=50, eval_set_loss = 2.233041928411889\n",
      "i=60, eval_set_loss = 2.2132829268134184\n",
      "i=70, eval_set_loss = 2.1981808581758386\n",
      "i=80, eval_set_loss = 2.186306750418791\n",
      "i=90, eval_set_loss = 2.176869729714203\n",
      "i=100, eval_set_loss = 2.1692412416383364\n",
      "i=110, eval_set_loss = 2.163561782158508\n",
      "i=120, eval_set_loss = 2.158905846595696\n",
      "i=130, eval_set_loss = 2.1549703860339315\n",
      "i=140, eval_set_loss = 2.1517306506498173\n",
      "i=150, eval_set_loss = 2.149116260168442\n",
      "i=160, eval_set_loss = 2.1470170504488086\n",
      "i=170, eval_set_loss = 2.1450708958003064\n",
      "i=180, eval_set_loss = 2.143155819554897\n",
      "i=190, eval_set_loss = 2.1420627536403707\n",
      "i=200, eval_set_loss = 2.1409605970186223\n",
      "i=210, eval_set_loss = 2.1400101269450764\n",
      "i=220, eval_set_loss = 2.1393014301589326\n",
      "i=230, eval_set_loss = 2.138452972667972\n",
      "i=240, eval_set_loss = 2.1378282954886068\n",
      "i=250, eval_set_loss = 2.137325337770827\n",
      "i=260, eval_set_loss = 2.137373329702214\n",
      "Stopping early: curr_loss of 2.137373329702214\n",
      "                                        exceeds compare_loss of 2.137325337770827\n",
      "Singleton weight = 0.3\n",
      "trial_number = 3\n",
      "i=0, eval_set_loss = 2.486129773506843\n",
      "i=10, eval_set_loss = 2.40021990233209\n",
      "i=20, eval_set_loss = 2.337089398012423\n",
      "i=30, eval_set_loss = 2.2908487264839406\n",
      "i=40, eval_set_loss = 2.2567952552320145\n",
      "i=50, eval_set_loss = 2.2312098559368425\n",
      "i=60, eval_set_loss = 2.211473940360304\n",
      "i=70, eval_set_loss = 2.1961440320322123\n",
      "i=80, eval_set_loss = 2.1846397248086427\n",
      "i=90, eval_set_loss = 2.1757244135599034\n",
      "i=100, eval_set_loss = 2.1682471179425944\n",
      "i=110, eval_set_loss = 2.1620733828189995\n",
      "i=120, eval_set_loss = 2.157320728035865\n",
      "i=130, eval_set_loss = 2.153182623033578\n",
      "i=140, eval_set_loss = 2.1500616046973495\n",
      "i=150, eval_set_loss = 2.1473644798165648\n",
      "i=160, eval_set_loss = 2.145133718982331\n",
      "i=170, eval_set_loss = 2.1430123119007924\n",
      "i=180, eval_set_loss = 2.141880855568504\n",
      "i=190, eval_set_loss = 2.140717767446424\n",
      "i=200, eval_set_loss = 2.1396490789710185\n",
      "i=210, eval_set_loss = 2.1386879252334876\n",
      "i=220, eval_set_loss = 2.137928511331205\n",
      "i=230, eval_set_loss = 2.1372757406678033\n",
      "i=240, eval_set_loss = 2.13695867946125\n",
      "i=250, eval_set_loss = 2.1367604990679983\n",
      "i=260, eval_set_loss = 2.1364743581251426\n",
      "i=270, eval_set_loss = 2.1364629455739976\n",
      "i=280, eval_set_loss = 2.1363097497048043\n",
      "i=290, eval_set_loss = 2.1365210078811288\n",
      "Stopping early: curr_loss of 2.1365210078811288\n",
      "                                        exceeds compare_loss of 2.1363097497048043\n",
      "Singleton weight = 0.4\n",
      "trial_number = 3\n",
      "i=0, eval_set_loss = 2.486129773506843\n",
      "i=10, eval_set_loss = 2.399153975727313\n",
      "i=20, eval_set_loss = 2.3355648394902784\n",
      "i=30, eval_set_loss = 2.289864935412141\n",
      "i=40, eval_set_loss = 2.2557011722707228\n",
      "i=50, eval_set_loss = 2.230607301854699\n",
      "i=60, eval_set_loss = 2.2106961062110835\n",
      "i=70, eval_set_loss = 2.196078009692763\n",
      "i=80, eval_set_loss = 2.1845765185375203\n",
      "i=90, eval_set_loss = 2.175555975599298\n",
      "i=100, eval_set_loss = 2.168051807773634\n",
      "i=110, eval_set_loss = 2.1623152953005773\n",
      "i=120, eval_set_loss = 2.1576080255565104\n",
      "i=130, eval_set_loss = 2.1541135260594366\n",
      "i=140, eval_set_loss = 2.1506767577411114\n",
      "i=150, eval_set_loss = 2.14809677079624\n",
      "i=160, eval_set_loss = 2.145943442728455\n",
      "i=170, eval_set_loss = 2.144154735348333\n",
      "i=180, eval_set_loss = 2.1427607478821122\n",
      "i=190, eval_set_loss = 2.141315255453468\n",
      "i=200, eval_set_loss = 2.1405034348725938\n",
      "i=210, eval_set_loss = 2.1393849310345354\n",
      "i=220, eval_set_loss = 2.138632559912224\n",
      "i=230, eval_set_loss = 2.1377925906337154\n",
      "i=240, eval_set_loss = 2.1373164877381168\n",
      "i=250, eval_set_loss = 2.136962769000001\n",
      "i=260, eval_set_loss = 2.13676826368295\n",
      "i=270, eval_set_loss = 2.136722086049195\n",
      "i=280, eval_set_loss = 2.136504052168629\n",
      "i=290, eval_set_loss = 2.1364554200965067\n",
      "i=300, eval_set_loss = 2.1365707637706843\n",
      "Stopping early: curr_loss of 2.1365707637706843\n",
      "                                        exceeds compare_loss of 2.1364554200965067\n",
      "Singleton weight = 0.5\n",
      "trial_number = 3\n",
      "i=0, eval_set_loss = 2.486129773506843\n",
      "i=10, eval_set_loss = 2.3979372487023056\n",
      "i=20, eval_set_loss = 2.333762494240127\n",
      "i=30, eval_set_loss = 2.287702575378788\n",
      "i=40, eval_set_loss = 2.25371150801273\n",
      "i=50, eval_set_loss = 2.2282300926203433\n",
      "i=60, eval_set_loss = 2.2087782012424495\n",
      "i=70, eval_set_loss = 2.1940450860019167\n",
      "i=80, eval_set_loss = 2.1826259792046856\n",
      "i=90, eval_set_loss = 2.173991656211809\n",
      "i=100, eval_set_loss = 2.166680360061374\n",
      "i=110, eval_set_loss = 2.160883424131188\n",
      "i=120, eval_set_loss = 2.1565619428774\n",
      "i=130, eval_set_loss = 2.1530071322269126\n",
      "i=140, eval_set_loss = 2.1497980880255003\n",
      "i=150, eval_set_loss = 2.1474088895009706\n",
      "i=160, eval_set_loss = 2.1453222874849236\n",
      "i=170, eval_set_loss = 2.1435816086765946\n",
      "i=180, eval_set_loss = 2.142106475560994\n",
      "i=190, eval_set_loss = 2.1407545587503183\n",
      "i=200, eval_set_loss = 2.1397982083202773\n",
      "i=210, eval_set_loss = 2.138923942702838\n",
      "i=220, eval_set_loss = 2.138226944754726\n",
      "i=230, eval_set_loss = 2.137598337406568\n",
      "i=240, eval_set_loss = 2.1372063549685243\n",
      "i=250, eval_set_loss = 2.136888526032562\n",
      "i=260, eval_set_loss = 2.1368198776749345\n",
      "i=270, eval_set_loss = 2.136664139615172\n",
      "i=280, eval_set_loss = 2.136751244839345\n",
      "Stopping early: curr_loss of 2.136751244839345\n",
      "                                        exceeds compare_loss of 2.136664139615172\n",
      "Singleton weight = 0.6\n",
      "trial_number = 3\n",
      "i=0, eval_set_loss = 2.486129773506843\n",
      "i=10, eval_set_loss = 2.3961852569042676\n",
      "i=20, eval_set_loss = 2.33190176800296\n",
      "i=30, eval_set_loss = 2.2860211517107367\n",
      "i=40, eval_set_loss = 2.2523874783862228\n",
      "i=50, eval_set_loss = 2.2272010684224406\n",
      "i=60, eval_set_loss = 2.2077693335943716\n",
      "i=70, eval_set_loss = 2.1929279196541174\n",
      "i=80, eval_set_loss = 2.181751720729952\n",
      "i=90, eval_set_loss = 2.1732981781060117\n",
      "i=100, eval_set_loss = 2.1660698334550856\n",
      "i=110, eval_set_loss = 2.1605453886082016\n",
      "i=120, eval_set_loss = 2.1559364480983203\n",
      "i=130, eval_set_loss = 2.152362917384163\n",
      "i=140, eval_set_loss = 2.149173170272676\n",
      "i=150, eval_set_loss = 2.1468320199719964\n",
      "i=160, eval_set_loss = 2.1449844977431134\n",
      "i=170, eval_set_loss = 2.1434710106518238\n",
      "i=180, eval_set_loss = 2.1420974394168204\n",
      "i=190, eval_set_loss = 2.1409976911122155\n",
      "i=200, eval_set_loss = 2.1402173520306023\n",
      "i=210, eval_set_loss = 2.139460702227037\n",
      "i=220, eval_set_loss = 2.138991271302393\n",
      "i=230, eval_set_loss = 2.13856561522931\n",
      "i=240, eval_set_loss = 2.1381205060776534\n",
      "i=250, eval_set_loss = 2.1377504663239133\n",
      "i=260, eval_set_loss = 2.1377510231110164\n",
      "Stopping early: curr_loss of 2.1377510231110164\n",
      "                                        exceeds compare_loss of 2.1377504663239133\n",
      "Singleton weight = 0.7\n",
      "trial_number = 3\n",
      "i=0, eval_set_loss = 2.486129773506843\n",
      "i=10, eval_set_loss = 2.3945880021714263\n",
      "i=20, eval_set_loss = 2.329808824347528\n",
      "i=30, eval_set_loss = 2.283934867620658\n",
      "i=40, eval_set_loss = 2.2504026059379654\n",
      "i=50, eval_set_loss = 2.225500696756617\n",
      "i=60, eval_set_loss = 2.2062037124150433\n",
      "i=70, eval_set_loss = 2.1914176291293606\n",
      "i=80, eval_set_loss = 2.1802394983780213\n",
      "i=90, eval_set_loss = 2.1718459913338624\n",
      "i=100, eval_set_loss = 2.1643847225255426\n",
      "i=110, eval_set_loss = 2.1589268653565616\n",
      "i=120, eval_set_loss = 2.154942215140008\n",
      "i=130, eval_set_loss = 2.1515407817889765\n",
      "i=140, eval_set_loss = 2.148577941486036\n",
      "i=150, eval_set_loss = 2.146456890652113\n",
      "i=160, eval_set_loss = 2.144471388555813\n",
      "i=170, eval_set_loss = 2.143039442779104\n",
      "i=180, eval_set_loss = 2.1419744459910026\n",
      "i=190, eval_set_loss = 2.1411444839369667\n",
      "i=200, eval_set_loss = 2.1404828478443476\n",
      "i=210, eval_set_loss = 2.1396118011008007\n",
      "i=220, eval_set_loss = 2.1390253057006654\n",
      "i=230, eval_set_loss = 2.138507874953618\n",
      "i=240, eval_set_loss = 2.1379887831977373\n",
      "i=250, eval_set_loss = 2.1377645494711643\n",
      "i=260, eval_set_loss = 2.1378034356667257\n",
      "Stopping early: curr_loss of 2.1378034356667257\n",
      "                                        exceeds compare_loss of 2.1377645494711643\n",
      "Singleton weight = 0.8\n",
      "trial_number = 3\n",
      "i=0, eval_set_loss = 2.486129773506843\n",
      "i=10, eval_set_loss = 2.3927273804422082\n",
      "i=20, eval_set_loss = 2.3273057063855265\n",
      "i=30, eval_set_loss = 2.2808508199691024\n",
      "i=40, eval_set_loss = 2.2472147843788868\n",
      "i=50, eval_set_loss = 2.222542490247693\n",
      "i=60, eval_set_loss = 2.204159343654138\n",
      "i=70, eval_set_loss = 2.1901747555768676\n",
      "i=80, eval_set_loss = 2.1790545736958973\n",
      "i=90, eval_set_loss = 2.1708500072405084\n",
      "i=100, eval_set_loss = 2.1638168989799516\n",
      "i=110, eval_set_loss = 2.15830866092522\n",
      "i=120, eval_set_loss = 2.1544819946129743\n",
      "i=130, eval_set_loss = 2.1509714092604724\n",
      "i=140, eval_set_loss = 2.148286974522497\n",
      "i=150, eval_set_loss = 2.14611157673323\n",
      "i=160, eval_set_loss = 2.14431872196963\n",
      "i=170, eval_set_loss = 2.142777952994214\n",
      "i=180, eval_set_loss = 2.141794146586705\n",
      "i=190, eval_set_loss = 2.14089071322943\n",
      "i=200, eval_set_loss = 2.1400894692888723\n",
      "i=210, eval_set_loss = 2.1395736861893186\n",
      "i=220, eval_set_loss = 2.1390828035173706\n",
      "i=230, eval_set_loss = 2.1385639270720618\n",
      "i=240, eval_set_loss = 2.138179782104015\n",
      "i=250, eval_set_loss = 2.137746012441989\n",
      "i=260, eval_set_loss = 2.1378701034488543\n",
      "Stopping early: curr_loss of 2.1378701034488543\n",
      "                                        exceeds compare_loss of 2.137746012441989\n",
      "Singleton weight = 0.9\n",
      "trial_number = 3\n",
      "i=0, eval_set_loss = 2.486129773506843\n",
      "i=10, eval_set_loss = 2.3903316633115455\n",
      "i=20, eval_set_loss = 2.324453984732348\n",
      "i=30, eval_set_loss = 2.277754193534352\n",
      "i=40, eval_set_loss = 2.244642522851211\n",
      "i=50, eval_set_loss = 2.220337087573241\n",
      "i=60, eval_set_loss = 2.201519644107337\n",
      "i=70, eval_set_loss = 2.187720236654464\n",
      "i=80, eval_set_loss = 2.1771327215471454\n",
      "i=90, eval_set_loss = 2.168905998707043\n",
      "i=100, eval_set_loss = 2.1623948464020972\n",
      "i=110, eval_set_loss = 2.157014558049376\n",
      "i=120, eval_set_loss = 2.1529929213235306\n",
      "i=130, eval_set_loss = 2.149886342971146\n",
      "i=140, eval_set_loss = 2.147226940686158\n",
      "i=150, eval_set_loss = 2.145300746566163\n",
      "i=160, eval_set_loss = 2.14356668483553\n",
      "i=170, eval_set_loss = 2.142534878265881\n",
      "i=180, eval_set_loss = 2.141604171489933\n",
      "i=190, eval_set_loss = 2.140660357349788\n",
      "i=200, eval_set_loss = 2.140172088930537\n",
      "i=210, eval_set_loss = 2.139473671985686\n",
      "i=220, eval_set_loss = 2.138971193646796\n",
      "i=230, eval_set_loss = 2.138595431218888\n",
      "i=240, eval_set_loss = 2.1381741880473895\n",
      "i=250, eval_set_loss = 2.1379491113237172\n",
      "i=260, eval_set_loss = 2.1382085759343643\n",
      "Stopping early: curr_loss of 2.1382085759343643\n",
      "                                        exceeds compare_loss of 2.1379491113237172\n",
      "Singleton weight = 1.0\n",
      "trial_number = 3\n",
      "i=0, eval_set_loss = 2.486129773506843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/xr46tkk15h10554_3mptdjlw0000gn/T/ipykernel_16166/2983974394.py:30: UserWarning: Some weights are not positive - may cause unexpected results\n",
      "  stb_tmp = stb.StructureBoostMulti(num_trees=2000, feature_configs=fc1, num_classes=12, target_structure=ts, learning_rate=.02)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=10, eval_set_loss = 2.3873079604589673\n",
      "i=20, eval_set_loss = 2.3205364537772257\n",
      "i=30, eval_set_loss = 2.274083950777217\n",
      "i=40, eval_set_loss = 2.2413766974856713\n",
      "i=50, eval_set_loss = 2.2177476643337046\n",
      "i=60, eval_set_loss = 2.1999127279400876\n",
      "i=70, eval_set_loss = 2.1863774879801894\n",
      "i=80, eval_set_loss = 2.1761850906094784\n",
      "i=90, eval_set_loss = 2.168213330508081\n",
      "i=100, eval_set_loss = 2.162438605139337\n",
      "i=110, eval_set_loss = 2.157520511491374\n",
      "i=120, eval_set_loss = 2.1537492219289676\n",
      "i=130, eval_set_loss = 2.1506422953506807\n",
      "i=140, eval_set_loss = 2.1477226361199135\n",
      "i=150, eval_set_loss = 2.1457967648458065\n",
      "i=160, eval_set_loss = 2.1442674552222316\n",
      "i=170, eval_set_loss = 2.142913336466971\n",
      "i=180, eval_set_loss = 2.14233281773165\n",
      "i=190, eval_set_loss = 2.1415587338265336\n",
      "i=200, eval_set_loss = 2.1409451443481946\n",
      "i=210, eval_set_loss = 2.1405315825681317\n",
      "i=220, eval_set_loss = 2.139963101658654\n",
      "i=230, eval_set_loss = 2.139790654551199\n",
      "i=240, eval_set_loss = 2.1395352166717383\n",
      "i=250, eval_set_loss = 2.139491737922947\n",
      "i=260, eval_set_loss = 2.1398433863447157\n",
      "Stopping early: curr_loss of 2.1398433863447157\n",
      "                                        exceeds compare_loss of 2.139491737922947\n",
      "Singleton weight = 0.0\n",
      "trial_number = 4\n",
      "i=0, eval_set_loss = 2.485709461624402\n",
      "i=10, eval_set_loss = 2.418225732334427\n",
      "i=20, eval_set_loss = 2.3639502098530074\n",
      "i=30, eval_set_loss = 2.3205457355722996\n",
      "i=40, eval_set_loss = 2.286843264277027\n",
      "i=50, eval_set_loss = 2.260381207876138\n",
      "i=60, eval_set_loss = 2.239623034997523\n",
      "i=70, eval_set_loss = 2.2233186570731625\n",
      "i=80, eval_set_loss = 2.210387635230078\n",
      "i=90, eval_set_loss = 2.2001755602154836\n",
      "i=100, eval_set_loss = 2.191854901013514\n",
      "i=110, eval_set_loss = 2.1851605349891927\n",
      "i=120, eval_set_loss = 2.1795591439829867\n",
      "i=130, eval_set_loss = 2.1750813989385196\n",
      "i=140, eval_set_loss = 2.1709795653540596\n",
      "i=150, eval_set_loss = 2.167844921988928\n",
      "i=160, eval_set_loss = 2.1650186802485534\n",
      "i=170, eval_set_loss = 2.162289225651186\n",
      "i=180, eval_set_loss = 2.160383641628562\n",
      "i=190, eval_set_loss = 2.1586763331730356\n",
      "i=200, eval_set_loss = 2.157001235551944\n",
      "i=210, eval_set_loss = 2.1556169056055863\n",
      "i=220, eval_set_loss = 2.154231057555045\n",
      "i=230, eval_set_loss = 2.1529781807186312\n",
      "i=240, eval_set_loss = 2.152038860484237\n",
      "i=250, eval_set_loss = 2.1512020844765973\n",
      "i=260, eval_set_loss = 2.1503019443717544\n",
      "i=270, eval_set_loss = 2.149371637011556\n",
      "i=280, eval_set_loss = 2.148670191165385\n",
      "i=290, eval_set_loss = 2.1481231739634326\n",
      "i=300, eval_set_loss = 2.1475278448286397\n",
      "i=310, eval_set_loss = 2.1473528202298118\n",
      "i=320, eval_set_loss = 2.146899858609033\n",
      "i=330, eval_set_loss = 2.1465972754617804\n",
      "i=340, eval_set_loss = 2.146224923490743\n",
      "i=350, eval_set_loss = 2.1459909360240976\n",
      "i=360, eval_set_loss = 2.1459699994729586\n",
      "i=370, eval_set_loss = 2.145628651438887\n",
      "i=380, eval_set_loss = 2.145392661445931\n",
      "i=390, eval_set_loss = 2.145029419332373\n",
      "i=400, eval_set_loss = 2.1449217547043795\n",
      "i=410, eval_set_loss = 2.1447204672841242\n",
      "i=420, eval_set_loss = 2.1446004548800675\n",
      "i=430, eval_set_loss = 2.144497011189482\n",
      "i=440, eval_set_loss = 2.144389273542059\n",
      "i=450, eval_set_loss = 2.1441600376208094\n",
      "i=460, eval_set_loss = 2.144006454635027\n",
      "i=470, eval_set_loss = 2.1439768849917615\n",
      "i=480, eval_set_loss = 2.143757551793012\n",
      "i=490, eval_set_loss = 2.1436497945693946\n",
      "i=500, eval_set_loss = 2.1439586236120625\n",
      "Stopping early: curr_loss of 2.1439586236120625\n",
      "                                        exceeds compare_loss of 2.1436497945693946\n",
      "Singleton weight = 0.1\n",
      "trial_number = 4\n",
      "i=0, eval_set_loss = 2.485709461624402\n",
      "i=10, eval_set_loss = 2.4024036831168227\n",
      "i=20, eval_set_loss = 2.340736425448983\n",
      "i=30, eval_set_loss = 2.294366978617047\n",
      "i=40, eval_set_loss = 2.260920401159655\n",
      "i=50, eval_set_loss = 2.235379537039178\n",
      "i=60, eval_set_loss = 2.2162908916245927\n",
      "i=70, eval_set_loss = 2.2019055021376372\n",
      "i=80, eval_set_loss = 2.190282957367281\n",
      "i=90, eval_set_loss = 2.180850118363054\n",
      "i=100, eval_set_loss = 2.1740174912268326\n",
      "i=110, eval_set_loss = 2.1684552493566804\n",
      "i=120, eval_set_loss = 2.163836594097518\n",
      "i=130, eval_set_loss = 2.1603265507695943\n",
      "i=140, eval_set_loss = 2.1573405414998814\n",
      "i=150, eval_set_loss = 2.154889023733\n",
      "i=160, eval_set_loss = 2.152718523040042\n",
      "i=170, eval_set_loss = 2.1509778886634403\n",
      "i=180, eval_set_loss = 2.1497392019418666\n",
      "i=190, eval_set_loss = 2.1488079837785588\n",
      "i=200, eval_set_loss = 2.1477993877577513\n",
      "i=210, eval_set_loss = 2.146929775862339\n",
      "i=220, eval_set_loss = 2.145875710014247\n",
      "i=230, eval_set_loss = 2.1450950307616448\n",
      "i=240, eval_set_loss = 2.1444545383613773\n",
      "i=250, eval_set_loss = 2.144014650164666\n",
      "i=260, eval_set_loss = 2.1437935507157477\n",
      "i=270, eval_set_loss = 2.143378028757553\n",
      "i=280, eval_set_loss = 2.1432589505854454\n",
      "i=290, eval_set_loss = 2.1430373208384292\n",
      "i=300, eval_set_loss = 2.142788686847274\n",
      "i=310, eval_set_loss = 2.14281577103706\n",
      "Stopping early: curr_loss of 2.14281577103706\n",
      "                                        exceeds compare_loss of 2.142788686847274\n",
      "Singleton weight = 0.2\n",
      "trial_number = 4\n",
      "i=0, eval_set_loss = 2.485709461624402\n",
      "i=10, eval_set_loss = 2.401538562081438\n",
      "i=20, eval_set_loss = 2.3395563229778027\n",
      "i=30, eval_set_loss = 2.293131587043361\n",
      "i=40, eval_set_loss = 2.259750383866033\n",
      "i=50, eval_set_loss = 2.234350507082235\n",
      "i=60, eval_set_loss = 2.215367811381972\n",
      "i=70, eval_set_loss = 2.2010854370933592\n",
      "i=80, eval_set_loss = 2.1895721185735435\n",
      "i=90, eval_set_loss = 2.1801389099853936\n",
      "i=100, eval_set_loss = 2.1732289428286067\n",
      "i=110, eval_set_loss = 2.1677593450516093\n",
      "i=120, eval_set_loss = 2.163270595898752\n",
      "i=130, eval_set_loss = 2.1596433085084317\n",
      "i=140, eval_set_loss = 2.156719863513244\n",
      "i=150, eval_set_loss = 2.1542233393883436\n",
      "i=160, eval_set_loss = 2.152097381407617\n",
      "i=170, eval_set_loss = 2.1503423979045277\n",
      "i=180, eval_set_loss = 2.149192036269224\n",
      "i=190, eval_set_loss = 2.147928655991863\n",
      "i=200, eval_set_loss = 2.1468729306963494\n",
      "i=210, eval_set_loss = 2.146029381934231\n",
      "i=220, eval_set_loss = 2.145221712187112\n",
      "i=230, eval_set_loss = 2.144508243386094\n",
      "i=240, eval_set_loss = 2.1440986113764002\n",
      "i=250, eval_set_loss = 2.1437883486073646\n",
      "i=260, eval_set_loss = 2.143633696106857\n",
      "i=270, eval_set_loss = 2.143256098268578\n",
      "i=280, eval_set_loss = 2.143117578785243\n",
      "i=290, eval_set_loss = 2.1432230150160323\n",
      "Stopping early: curr_loss of 2.1432230150160323\n",
      "                                        exceeds compare_loss of 2.143117578785243\n",
      "Singleton weight = 0.3\n",
      "trial_number = 4\n",
      "i=0, eval_set_loss = 2.485709461624402\n",
      "i=10, eval_set_loss = 2.400566222997118\n",
      "i=20, eval_set_loss = 2.3382413190091924\n",
      "i=30, eval_set_loss = 2.2917709410752383\n",
      "i=40, eval_set_loss = 2.2582321605305014\n",
      "i=50, eval_set_loss = 2.2328050033877473\n",
      "i=60, eval_set_loss = 2.2131731057856223\n",
      "i=70, eval_set_loss = 2.1989469337283096\n",
      "i=80, eval_set_loss = 2.18755742537943\n",
      "i=90, eval_set_loss = 2.1787171200096447\n",
      "i=100, eval_set_loss = 2.171734445184763\n",
      "i=110, eval_set_loss = 2.1665053548599498\n",
      "i=120, eval_set_loss = 2.1619995320113565\n",
      "i=130, eval_set_loss = 2.1583874425297136\n",
      "i=140, eval_set_loss = 2.1556087182966106\n",
      "i=150, eval_set_loss = 2.1532177027435266\n",
      "i=160, eval_set_loss = 2.1513015338111114\n",
      "i=170, eval_set_loss = 2.1496012040640258\n",
      "i=180, eval_set_loss = 2.1482431065946255\n",
      "i=190, eval_set_loss = 2.147364510411976\n",
      "i=200, eval_set_loss = 2.1462758958134147\n",
      "i=210, eval_set_loss = 2.1456317838057206\n",
      "i=220, eval_set_loss = 2.1448601672084115\n",
      "i=230, eval_set_loss = 2.1441284758405184\n",
      "i=240, eval_set_loss = 2.143689433970943\n",
      "i=250, eval_set_loss = 2.1435296359451037\n",
      "i=260, eval_set_loss = 2.1431421315649377\n",
      "i=270, eval_set_loss = 2.1427321779091515\n",
      "i=280, eval_set_loss = 2.1427225397051703\n",
      "i=290, eval_set_loss = 2.1424360009677494\n",
      "i=300, eval_set_loss = 2.142035575475864\n",
      "i=310, eval_set_loss = 2.142119249126225\n",
      "Stopping early: curr_loss of 2.142119249126225\n",
      "                                        exceeds compare_loss of 2.142035575475864\n",
      "Singleton weight = 0.4\n",
      "trial_number = 4\n",
      "i=0, eval_set_loss = 2.485709461624402\n",
      "i=10, eval_set_loss = 2.399527156713769\n",
      "i=20, eval_set_loss = 2.3367473431449435\n",
      "i=30, eval_set_loss = 2.290109747962125\n",
      "i=40, eval_set_loss = 2.2569283709329544\n",
      "i=50, eval_set_loss = 2.23167902798212\n",
      "i=60, eval_set_loss = 2.2125587837162404\n",
      "i=70, eval_set_loss = 2.198064969875895\n",
      "i=80, eval_set_loss = 2.186775769923306\n",
      "i=90, eval_set_loss = 2.178046011497727\n",
      "i=100, eval_set_loss = 2.171339224351314\n",
      "i=110, eval_set_loss = 2.1663062398110133\n",
      "i=120, eval_set_loss = 2.1620406012582856\n",
      "i=130, eval_set_loss = 2.1588205390713964\n",
      "i=140, eval_set_loss = 2.1557475361979517\n",
      "i=150, eval_set_loss = 2.153409968888281\n",
      "i=160, eval_set_loss = 2.151415363799456\n",
      "i=170, eval_set_loss = 2.149950357163705\n",
      "i=180, eval_set_loss = 2.1489484945527315\n",
      "i=190, eval_set_loss = 2.1478159969414103\n",
      "i=200, eval_set_loss = 2.1470409233577668\n",
      "i=210, eval_set_loss = 2.146345949243292\n",
      "i=220, eval_set_loss = 2.145291542366364\n",
      "i=230, eval_set_loss = 2.144578214158301\n",
      "i=240, eval_set_loss = 2.144020709322602\n",
      "i=250, eval_set_loss = 2.1437221439126084\n",
      "i=260, eval_set_loss = 2.1433419294670273\n",
      "i=270, eval_set_loss = 2.1431147133025195\n",
      "i=280, eval_set_loss = 2.143197096407486\n",
      "Stopping early: curr_loss of 2.143197096407486\n",
      "                                        exceeds compare_loss of 2.1431147133025195\n",
      "Singleton weight = 0.5\n",
      "trial_number = 4\n",
      "i=0, eval_set_loss = 2.485709461624402\n",
      "i=10, eval_set_loss = 2.39835509147157\n",
      "i=20, eval_set_loss = 2.3351381766896533\n",
      "i=30, eval_set_loss = 2.2884761424203846\n",
      "i=40, eval_set_loss = 2.255474087236251\n",
      "i=50, eval_set_loss = 2.230164984914516\n",
      "i=60, eval_set_loss = 2.2114960584236347\n",
      "i=70, eval_set_loss = 2.197545340058933\n",
      "i=80, eval_set_loss = 2.1864043615864146\n",
      "i=90, eval_set_loss = 2.1775680008556213\n",
      "i=100, eval_set_loss = 2.1709106409548613\n",
      "i=110, eval_set_loss = 2.165703041458903\n",
      "i=120, eval_set_loss = 2.1610852520380925\n",
      "i=130, eval_set_loss = 2.1578661173911264\n",
      "i=140, eval_set_loss = 2.1548698766652223\n",
      "i=150, eval_set_loss = 2.1529357483567635\n",
      "i=160, eval_set_loss = 2.151015248933058\n",
      "i=170, eval_set_loss = 2.149467787891814\n",
      "i=180, eval_set_loss = 2.148420292155556\n",
      "i=190, eval_set_loss = 2.147252057459768\n",
      "i=200, eval_set_loss = 2.146727781235155\n",
      "i=210, eval_set_loss = 2.1456571302831953\n",
      "i=220, eval_set_loss = 2.145220306667135\n",
      "i=230, eval_set_loss = 2.1445514709188194\n",
      "i=240, eval_set_loss = 2.144229847304978\n",
      "i=250, eval_set_loss = 2.1442661420611144\n",
      "Stopping early: curr_loss of 2.1442661420611144\n",
      "                                        exceeds compare_loss of 2.144229847304978\n",
      "Singleton weight = 0.6\n",
      "trial_number = 4\n",
      "i=0, eval_set_loss = 2.485709461624402\n",
      "i=10, eval_set_loss = 2.396904438901004\n",
      "i=20, eval_set_loss = 2.333255291906944\n",
      "i=30, eval_set_loss = 2.2865137076855544\n",
      "i=40, eval_set_loss = 2.253388400001442\n",
      "i=50, eval_set_loss = 2.228320153002847\n",
      "i=60, eval_set_loss = 2.2096203491194415\n",
      "i=70, eval_set_loss = 2.1959138844240793\n",
      "i=80, eval_set_loss = 2.1849309829403594\n",
      "i=90, eval_set_loss = 2.1767049837870944\n",
      "i=100, eval_set_loss = 2.1701130259196106\n",
      "i=110, eval_set_loss = 2.1651880746126175\n",
      "i=120, eval_set_loss = 2.16107613244066\n",
      "i=130, eval_set_loss = 2.1577925748323263\n",
      "i=140, eval_set_loss = 2.154848183008671\n",
      "i=150, eval_set_loss = 2.152649966706969\n",
      "i=160, eval_set_loss = 2.151031929855007\n",
      "i=170, eval_set_loss = 2.1494252137322825\n",
      "i=180, eval_set_loss = 2.1485440030892\n",
      "i=190, eval_set_loss = 2.1476280982712663\n",
      "i=200, eval_set_loss = 2.1466106003216163\n",
      "i=210, eval_set_loss = 2.1458966197154195\n",
      "i=220, eval_set_loss = 2.1451154637327554\n",
      "i=230, eval_set_loss = 2.1447787458606014\n",
      "i=240, eval_set_loss = 2.144283373711737\n",
      "i=250, eval_set_loss = 2.1443022742092737\n",
      "Stopping early: curr_loss of 2.1443022742092737\n",
      "                                        exceeds compare_loss of 2.144283373711737\n",
      "Singleton weight = 0.7\n",
      "trial_number = 4\n",
      "i=0, eval_set_loss = 2.485709461624402\n",
      "i=10, eval_set_loss = 2.395583507246717\n",
      "i=20, eval_set_loss = 2.331453804957633\n",
      "i=30, eval_set_loss = 2.2854953542958034\n",
      "i=40, eval_set_loss = 2.252332445457514\n",
      "i=50, eval_set_loss = 2.2275518212758945\n",
      "i=60, eval_set_loss = 2.2089613131550845\n",
      "i=70, eval_set_loss = 2.1948357993087644\n",
      "i=80, eval_set_loss = 2.1841878666794328\n",
      "i=90, eval_set_loss = 2.1756293671448117\n",
      "i=100, eval_set_loss = 2.1693788818038673\n",
      "i=110, eval_set_loss = 2.164135483744627\n",
      "i=120, eval_set_loss = 2.1602306752798075\n",
      "i=130, eval_set_loss = 2.1571454475844223\n",
      "i=140, eval_set_loss = 2.154229183228527\n",
      "i=150, eval_set_loss = 2.1525546718256345\n",
      "i=160, eval_set_loss = 2.151089166674188\n",
      "i=170, eval_set_loss = 2.149761320958\n",
      "i=180, eval_set_loss = 2.1489197635307034\n",
      "i=190, eval_set_loss = 2.148238819693681\n",
      "i=200, eval_set_loss = 2.147796454642321\n",
      "i=210, eval_set_loss = 2.1473524248875075\n",
      "i=220, eval_set_loss = 2.1466157124931295\n",
      "i=230, eval_set_loss = 2.146151001389007\n",
      "i=240, eval_set_loss = 2.14580508076138\n",
      "i=250, eval_set_loss = 2.145771846663376\n",
      "i=260, eval_set_loss = 2.145653194404656\n",
      "i=270, eval_set_loss = 2.145150554246449\n",
      "i=280, eval_set_loss = 2.14501576736055\n",
      "i=290, eval_set_loss = 2.1453797039951605\n",
      "Stopping early: curr_loss of 2.1453797039951605\n",
      "                                        exceeds compare_loss of 2.14501576736055\n",
      "Singleton weight = 0.8\n",
      "trial_number = 4\n",
      "i=0, eval_set_loss = 2.485709461624402\n",
      "i=10, eval_set_loss = 2.3937431577347916\n",
      "i=20, eval_set_loss = 2.329171244243451\n",
      "i=30, eval_set_loss = 2.2831420103393274\n",
      "i=40, eval_set_loss = 2.250121883952791\n",
      "i=50, eval_set_loss = 2.225551247529818\n",
      "i=60, eval_set_loss = 2.2070222113371214\n",
      "i=70, eval_set_loss = 2.193160525033633\n",
      "i=80, eval_set_loss = 2.1826715228168685\n",
      "i=90, eval_set_loss = 2.1744181852878626\n",
      "i=100, eval_set_loss = 2.168305772207259\n",
      "i=110, eval_set_loss = 2.1633779696705866\n",
      "i=120, eval_set_loss = 2.159536136396904\n",
      "i=130, eval_set_loss = 2.1565236942928587\n",
      "i=140, eval_set_loss = 2.1539332986382402\n",
      "i=150, eval_set_loss = 2.15212892698609\n",
      "i=160, eval_set_loss = 2.150633685385636\n",
      "i=170, eval_set_loss = 2.1490832124393253\n",
      "i=180, eval_set_loss = 2.1483260142857397\n",
      "i=190, eval_set_loss = 2.147789372276014\n",
      "i=200, eval_set_loss = 2.147166268413588\n",
      "i=210, eval_set_loss = 2.1466318867760443\n",
      "i=220, eval_set_loss = 2.1459873872473842\n",
      "i=230, eval_set_loss = 2.145635818087609\n",
      "i=240, eval_set_loss = 2.1453169820017997\n",
      "i=250, eval_set_loss = 2.1448052291680253\n",
      "i=260, eval_set_loss = 2.144471913689169\n",
      "i=270, eval_set_loss = 2.144164582928809\n",
      "i=280, eval_set_loss = 2.144159211425934\n",
      "i=290, eval_set_loss = 2.144234435254359\n",
      "Stopping early: curr_loss of 2.144234435254359\n",
      "                                        exceeds compare_loss of 2.144159211425934\n",
      "Singleton weight = 0.9\n",
      "trial_number = 4\n",
      "i=0, eval_set_loss = 2.485709461624402\n",
      "i=10, eval_set_loss = 2.391505937958283\n",
      "i=20, eval_set_loss = 2.3264169038165274\n",
      "i=30, eval_set_loss = 2.2797999000092624\n",
      "i=40, eval_set_loss = 2.2471108677044107\n",
      "i=50, eval_set_loss = 2.2233379803495\n",
      "i=60, eval_set_loss = 2.2048664630265815\n",
      "i=70, eval_set_loss = 2.1920630270746124\n",
      "i=80, eval_set_loss = 2.1818502930451817\n",
      "i=90, eval_set_loss = 2.173554411979756\n",
      "i=100, eval_set_loss = 2.16792556019284\n",
      "i=110, eval_set_loss = 2.1633048004665185\n",
      "i=120, eval_set_loss = 2.1596334382064906\n",
      "i=130, eval_set_loss = 2.1570979709275764\n",
      "i=140, eval_set_loss = 2.1545566595353756\n",
      "i=150, eval_set_loss = 2.152863893781181\n",
      "i=160, eval_set_loss = 2.1513712049031732\n",
      "i=170, eval_set_loss = 2.1501819154147896\n",
      "i=180, eval_set_loss = 2.149398881839123\n",
      "i=190, eval_set_loss = 2.14873416671444\n",
      "i=200, eval_set_loss = 2.1483746142614057\n",
      "i=210, eval_set_loss = 2.1477024104329363\n",
      "i=220, eval_set_loss = 2.147212386692669\n",
      "i=230, eval_set_loss = 2.146825185263011\n",
      "i=240, eval_set_loss = 2.146583365196859\n",
      "i=250, eval_set_loss = 2.1468063312573085\n",
      "Stopping early: curr_loss of 2.1468063312573085\n",
      "                                        exceeds compare_loss of 2.146583365196859\n",
      "Singleton weight = 1.0\n",
      "trial_number = 4\n",
      "i=0, eval_set_loss = 2.485709461624402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q8/xr46tkk15h10554_3mptdjlw0000gn/T/ipykernel_16166/2983974394.py:30: UserWarning: Some weights are not positive - may cause unexpected results\n",
      "  stb_tmp = stb.StructureBoostMulti(num_trees=2000, feature_configs=fc1, num_classes=12, target_structure=ts, learning_rate=.02)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=10, eval_set_loss = 2.3886671834675517\n",
      "i=20, eval_set_loss = 2.323880926796148\n",
      "i=30, eval_set_loss = 2.2770880896035783\n",
      "i=40, eval_set_loss = 2.2448505569309245\n",
      "i=50, eval_set_loss = 2.221099116338714\n",
      "i=60, eval_set_loss = 2.2035573206243986\n",
      "i=70, eval_set_loss = 2.1909710006760386\n",
      "i=80, eval_set_loss = 2.180800477430217\n",
      "i=90, eval_set_loss = 2.173025579693591\n",
      "i=100, eval_set_loss = 2.1673336531924448\n",
      "i=110, eval_set_loss = 2.1629991002648623\n",
      "i=120, eval_set_loss = 2.159334615797148\n",
      "i=130, eval_set_loss = 2.1570434962401137\n",
      "i=140, eval_set_loss = 2.154649704419218\n",
      "i=150, eval_set_loss = 2.1528211878142525\n",
      "i=160, eval_set_loss = 2.151600433669546\n",
      "i=170, eval_set_loss = 2.150514183331752\n",
      "i=180, eval_set_loss = 2.150059245722301\n",
      "i=190, eval_set_loss = 2.149300110781176\n",
      "i=200, eval_set_loss = 2.149087390857483\n",
      "i=210, eval_set_loss = 2.1486419533928443\n",
      "i=220, eval_set_loss = 2.148237750460858\n",
      "i=230, eval_set_loss = 2.1479233997931324\n",
      "i=240, eval_set_loss = 2.1476147242733568\n",
      "i=250, eval_set_loss = 2.147511350437197\n",
      "i=260, eval_set_loss = 2.147507031919985\n",
      "i=270, eval_set_loss = 2.147169948160244\n",
      "i=280, eval_set_loss = 2.1474912249783604\n",
      "Stopping early: curr_loss of 2.1474912249783604\n",
      "                                        exceeds compare_loss of 2.147169948160244\n"
     ]
    }
   ],
   "source": [
    "train_size = 5000\n",
    "valid_size = 5000\n",
    "test_size = 100000\n",
    "num_trials= 5\n",
    "sw_vec = np.arange(0,11)/10\n",
    "\n",
    "ll_mat = np.zeros((num_trials, len(sw_vec)))\n",
    "acc_mat = np.zeros((num_trials, len(sw_vec)))\n",
    "\n",
    "\n",
    "for tr in range(num_trials):\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X,y,test_size=test_size, random_state=42+tr)\n",
    "    X_train_rem, X_valid, y_train_rem, y_valid = train_test_split(X_train_val, y_train_val, test_size=valid_size, random_state=42+tr)\n",
    "    X_train, X_rem, y_train, y_rem = train_test_split(X_train_rem, y_train_rem, train_size=train_size, random_state=42+tr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for i,sw in enumerate(sw_vec):\n",
    "        print('Singleton weight = {}'.format(sw))\n",
    "        print('trial_number = {}'.format(tr))\n",
    "        ts = {}\n",
    "        ts['partition_type'] = 'fixed'\n",
    "        ts['partition_list'] = [ [[0,1,2],[3,4,5],[6,7,8],[9,10,11]],\n",
    "                                 [[1,2,3],[4,5,6],[7,8,9],[10,11,0]],\n",
    "                                 [[2,3,4],[5,6,7],[8,9,10],[11,0,1]] ]\n",
    "        ts['singleton_weight'] = sw\n",
    "        rem = (1-sw)/3\n",
    "        ts['partition_weight_vec'] = [rem, rem, rem]\n",
    "        stb_tmp = stb.StructureBoostMulti(num_trees=2000, feature_configs=fc1, num_classes=12, target_structure=ts, learning_rate=.02)\n",
    "        stb_tmp.fit(X_train,y_train, eval_set=(X_valid, y_valid), early_stop_past_steps=1, eval_freq=10)\n",
    "        preds_tmp = stb_tmp.predict_proba(X_test)\n",
    "        ll = log_loss(y_test, preds_tmp)\n",
    "        hard_preds = np.argmax(preds_tmp,axis=1)\n",
    "        acc = accuracy_score(y_test,hard_preds)\n",
    "        ll_mat[tr,i] = ll\n",
    "        acc_mat[tr,i] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x138e788e0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ll_vec = np.mean(ll_mat, axis=0)\n",
    "plt.plot(sw_vec, ll_vec, marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x138fde880>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_vec = np.mean(acc_mat, axis=0)\n",
    "plt.plot(sw_vec, acc_vec, marker='o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
